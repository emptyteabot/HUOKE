"""
å®Œæ•´è·å®¢ç³»ç»Ÿ - ä¿¡å·é©±åŠ¨ç‰ˆæœ¬ (ç•™å­¦è¡Œä¸šä¸“ç”¨)

åŠŸèƒ½:
1. å¤šå¹³å°æŠ“å–å®¢æˆ·æ•°æ® (å°çº¢ä¹¦ã€çŸ¥ä¹ã€å¾®åšç­‰)
2. ä¿¡å·æ£€æµ‹ä¸æ„å›¾è¯†åˆ« (è¡Œä¸º/æŠ€æœ¯/äººå‘˜ä¿¡å·)
3. AIæ™ºèƒ½çº¿ç´¢è¯„åˆ†ä¸æ•°æ®å¯ŒåŒ–
4. è¶…ä¸ªæ€§åŒ–é‚®ä»¶ç”Ÿæˆ (ä¿¡å·é©±åŠ¨è¯æœ¯)
5. é‡åŒ–æ·˜æ±°æœºåˆ¶ (200æ¬¡è§¦è¾¾æ­¢æŸçº¿)
6. å¤šæ¬¡è§¦è¾¾åºåˆ—è‡ªåŠ¨åŒ–

ä½¿ç”¨æ–¹æ³•:
python lead_generation_complete.py
"""

import time
import random
import json
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import os
import sys
import re
import requests

# å¯¼å…¥å·²æœ‰æ¨¡å—
try:
    from lead_scoring import LeadScoringSystem
    from china_social_scraper import ChinaSocialScraper
    import undetected_chromedriver as uc
    from selenium.webdriver.common.by import By
    SELENIUM_AVAILABLE = True
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("è¯·å®‰è£…: pip install selenium undetected-chromedriver pandas openpyxl openai")
    SELENIUM_AVAILABLE = False


# ============================================================
# ä¿¡å·é©±åŠ¨ç³»ç»Ÿ - ç•™å­¦è¡Œä¸šä¸“ç”¨
# ============================================================

class SignalType(Enum):
    """ä¿¡å·ç±»å‹"""
    BEHAVIOR = "è¡Œä¸ºä¿¡å·"      # ç”¨æˆ·è¡Œä¸ºè½¨è¿¹
    TECHNICAL = "æŠ€æœ¯ä¿¡å·"     # æŠ€æœ¯æ ˆå˜åŠ¨
    PERSONNEL = "äººäº‹ä¿¡å·"     # äººäº‹å˜åŠ¨


class UrgencyLevel(Enum):
    """ç´§è¿«åº¦ç­‰çº§"""
    CRITICAL = "æé«˜"    # ç«‹å³å‡ºå‡»
    HIGH = "é«˜"          # 24å°æ—¶å†…
    MEDIUM = "ä¸­"        # 3å¤©å†…
    LOW = "ä½"           # 1å‘¨å†…


@dataclass
class IntentSignal:
    """æ„å›¾ä¿¡å·æ•°æ®ç»“æ„"""
    signal_type: SignalType
    signal_name: str
    company: str
    contact_person: Optional[str]
    detected_at: datetime
    urgency: UrgencyLevel
    confidence: float  # 0-1
    raw_data: Dict
    pain_point: str    # æ¨æ–­çš„ç—›ç‚¹
    financial_loss: str  # æ¨æ–­çš„è´¢åŠ¡æŸå¤±

    def to_dict(self) -> Dict:
        return {
            'signal_type': self.signal_type.value,
            'signal_name': self.signal_name,
            'company': self.company,
            'contact_person': self.contact_person,
            'detected_at': self.detected_at.isoformat(),
            'urgency': self.urgency.value,
            'confidence': self.confidence,
            'raw_data': self.raw_data,
            'pain_point': self.pain_point,
            'financial_loss': self.financial_loss
        }


class StudyAbroadSignalDetector:
    """ç•™å­¦è¡Œä¸šä¿¡å·æ£€æµ‹å™¨"""

    def __init__(self):
        # ç•™å­¦è¡Œä¸šç‰¹å®šä¿¡å·æ¨¡å¼
        self.signal_patterns = {
            'æœç´¢ç•™å­¦ç”³è¯·': {
                'keywords': ['ç•™å­¦ç”³è¯·', 'å‡ºå›½è¯»ç ”', 'æœ¬ç§‘ç•™å­¦', 'ç ”ç©¶ç”Ÿç”³è¯·', 'åšå£«ç”³è¯·'],
                'urgency': UrgencyLevel.HIGH,
                'pain_point': 'æ­£åœ¨ä¸»åŠ¨æœç´¢ç•™å­¦ä¿¡æ¯,å¤„äºå†³ç­–çª—å£æœŸ',
                'financial_loss': 'é”™è¿‡ç”³è¯·å­£,å»¶è¯¯ä¸€å¹´æ—¶é—´æˆæœ¬'
            },
            'å’¨è¯¢è¯­è¨€è€ƒè¯•': {
                'keywords': ['é›…æ€', 'æ‰˜ç¦', 'gre', 'gmat', 'è¯­è¨€è€ƒè¯•', 'è€ƒè¯•åŸ¹è®­'],
                'urgency': UrgencyLevel.CRITICAL,
                'pain_point': 'è¯­è¨€æˆç»©æ˜¯ç”³è¯·é—¨æ§›,æ€¥éœ€æåˆ†',
                'financial_loss': 'æˆç»©ä¸è¾¾æ ‡,æ— æ³•ç”³è¯·ç›®æ ‡é™¢æ ¡'
            },
            'è¯¢é—®ç”³è¯·æ¡ä»¶': {
                'keywords': ['ç”³è¯·æ¡ä»¶', 'gpaè¦æ±‚', 'å½•å–è¦æ±‚', 'èƒ½ä¸èƒ½ç”³è¯·', 'å¤Ÿä¸å¤Ÿ'],
                'urgency': UrgencyLevel.HIGH,
                'pain_point': 'ä¸ç¡®å®šè‡ªèº«æ¡ä»¶,éœ€è¦ä¸“ä¸šè¯„ä¼°',
                'financial_loss': 'ç›²ç›®ç”³è¯·,æµªè´¹ç”³è¯·è´¹å’Œæ—¶é—´'
            },
            'è´¹ç”¨ç„¦è™‘': {
                'keywords': ['è´¹ç”¨', 'å¤šå°‘é’±', 'é¢„ç®—', 'å¥–å­¦é‡‘', 'è´·æ¬¾', 'è´Ÿæ‹…å¾—èµ·'],
                'urgency': UrgencyLevel.MEDIUM,
                'pain_point': 'æ‹…å¿ƒç•™å­¦è´¹ç”¨è¿‡é«˜,éœ€è¦è´¢åŠ¡è§„åˆ’',
                'financial_loss': 'æ²¡æœ‰åˆç†è§„åˆ’,å¯èƒ½æ”¾å¼ƒç•™å­¦æœºä¼š'
            },
            'æ—¶é—´ç´§è¿«': {
                'keywords': ['æ¥å¾—åŠ', 'æ™šä¸æ™š', 'ä»€ä¹ˆæ—¶å€™å¼€å§‹', 'æˆªæ­¢æ—¶é—´', 'èµ¶ä¸èµ¶'],
                'urgency': UrgencyLevel.CRITICAL,
                'pain_point': 'æ—¶é—´ç´§è¿«,éœ€è¦å¿«é€Ÿè§„åˆ’',
                'financial_loss': 'é”™è¿‡ç”³è¯·æˆªæ­¢æ—¥æœŸ,å»¶è¯¯ä¸€å¹´'
            },
            'ä¸“ä¸šé€‰æ‹©': {
                'keywords': ['ä»€ä¹ˆä¸“ä¸š', 'ä¸“ä¸šæ¨è', 'å­¦ä»€ä¹ˆå¥½', 'ä¸“ä¸šæ’å', 'å°±ä¸šå‰æ™¯'],
                'urgency': UrgencyLevel.MEDIUM,
                'pain_point': 'ä¸“ä¸šé€‰æ‹©è¿·èŒ«,éœ€è¦èŒä¸šè§„åˆ’',
                'financial_loss': 'é€‰é”™ä¸“ä¸š,å½±å“æœªæ¥èŒä¸šå‘å±•'
            },
            'é™¢æ ¡å’¨è¯¢': {
                'keywords': ['å­¦æ ¡æ¨è', 'å¤§å­¦æ’å', 'å“ªä¸ªå­¦æ ¡å¥½', 'é™¢æ ¡é€‰æ‹©'],
                'urgency': UrgencyLevel.HIGH,
                'pain_point': 'ä¸äº†è§£é™¢æ ¡æƒ…å†µ,éœ€è¦ä¸“ä¸šå»ºè®®',
                'financial_loss': 'é€‰æ‹©ä¸åŒ¹é…é™¢æ ¡,å½±å“å½•å–ç‡'
            },
            'æˆåŠŸæ¡ˆä¾‹': {
                'keywords': ['æ¡ˆä¾‹', 'ç»éªŒåˆ†äº«', 'æˆåŠŸç”³è¯·', 'æ‹¿åˆ°offer', 'å½•å–'],
                'urgency': UrgencyLevel.MEDIUM,
                'pain_point': 'éœ€è¦å‚è€ƒæˆåŠŸæ¡ˆä¾‹,å¢å¼ºä¿¡å¿ƒ',
                'financial_loss': 'ç¼ºä¹ç»éªŒæŒ‡å¯¼,ç”³è¯·æˆåŠŸç‡ä½'
            }
        }

    def detect_from_content(self, content: str, author: str, platform: str, url: str = '') -> Optional[IntentSignal]:
        """ä»å†…å®¹æ£€æµ‹ä¿¡å·"""
        content_lower = content.lower()

        for signal_name, pattern in self.signal_patterns.items():
            # å…³é”®è¯åŒ¹é…
            matched_keywords = [kw for kw in pattern['keywords'] if kw in content_lower]

            if matched_keywords:
                confidence = min(len(matched_keywords) / len(pattern['keywords']), 1.0)

                return IntentSignal(
                    signal_type=SignalType.BEHAVIOR,
                    signal_name=f"{platform}-{signal_name}",
                    company=self._extract_institution(content),
                    contact_person=author,
                    detected_at=datetime.now(),
                    urgency=pattern['urgency'],
                    confidence=confidence,
                    raw_data={
                        'platform': platform,
                        'content': content[:200],
                        'url': url,
                        'matched_keywords': matched_keywords
                    },
                    pain_point=pattern['pain_point'],
                    financial_loss=pattern['financial_loss']
                )

        return None

    def _extract_institution(self, text: str) -> str:
        """ä»æ–‡æœ¬æå–æœºæ„å"""
        # ç®€åŒ–ç‰ˆ,å®é™…åº”ä½¿ç”¨NER
        institution_keywords = ['ç•™å­¦æœºæ„', 'ä¸­ä»‹', 'å’¨è¯¢å…¬å¸', 'æ•™è‚²æœºæ„']
        for keyword in institution_keywords:
            if keyword in text:
                return "ç•™å­¦æœºæ„"
        return "ä¸ªäººå­¦ç”Ÿ"


class StrategyMetrics:
    """ç­–ç•¥æŒ‡æ ‡è¿½è¸ª"""

    def __init__(self, strategy_id: str):
        self.strategy_id = strategy_id
        self.total_sent = 0
        self.delivered = 0
        self.opened = 0
        self.replied = 0
        self.mql = 0
        self.sql = 0
        self.closed = 0

    @property
    def delivery_rate(self) -> float:
        return self.delivered / self.total_sent if self.total_sent > 0 else 0

    @property
    def open_rate(self) -> float:
        return self.opened / self.delivered if self.delivered > 0 else 0

    @property
    def reply_rate(self) -> float:
        return self.replied / self.delivered if self.delivered > 0 else 0

    def should_eliminate(self, stop_loss_threshold: float = 0.02, min_sample_size: int = 200) -> tuple:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ·˜æ±°"""
        # æ ·æœ¬é‡ä¸è¶³,ç»§ç»­è§‚å¯Ÿ
        if self.total_sent < min_sample_size:
            return False, f"æ ·æœ¬é‡ä¸è¶³({self.total_sent}/{min_sample_size}),ç»§ç»­è§‚å¯Ÿ"

        # å›å¤ç‡ä½äºæ­¢æŸçº¿
        if self.reply_rate < stop_loss_threshold:
            return True, f"å›å¤ç‡{self.reply_rate*100:.2f}%ä½äºæ­¢æŸçº¿{stop_loss_threshold*100}%"

        # é€è¾¾ç‡è¿‡ä½
        if self.delivery_rate < 0.8:
            return True, f"é€è¾¾ç‡{self.delivery_rate*100:.1f}%è¿‡ä½"

        return False, "ç­–ç•¥è¡¨ç°æ­£å¸¸"


class DeepSeekEmailGenerator:
    """DeepSeek APIé‚®ä»¶ç”Ÿæˆå™¨"""

    def __init__(self, api_key: str = "sk-d86589fb80f248cea3f4a843eaebce5a"):
        self.api_key = api_key
        self.api_url = "https://api.deepseek.com/v1/chat/completions"

    def generate_signal_driven_email(self, signal: IntentSignal, lead: Dict) -> Dict:
        """åŸºäºä¿¡å·ç”Ÿæˆä¸ªæ€§åŒ–é‚®ä»¶"""

        name = lead.get('username', 'åŒå­¦')
        content = lead.get('content', '')

        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç•™å­¦é¡¾é—®,éœ€è¦æ ¹æ®å­¦ç”Ÿçš„æ„å›¾ä¿¡å·ç”Ÿæˆä¸€å°ä¸ªæ€§åŒ–é‚®ä»¶ã€‚

ã€å­¦ç”Ÿä¿¡æ¯ã€‘
å§“å: {name}
å‘å¸ƒå†…å®¹: {content[:200]}

ã€æ£€æµ‹åˆ°çš„ä¿¡å·ã€‘
ä¿¡å·ç±»å‹: {signal.signal_name}
ç´§è¿«åº¦: {signal.urgency.value}
ç—›ç‚¹: {signal.pain_point}
æ½œåœ¨æŸå¤±: {signal.financial_loss}

ã€é‚®ä»¶è¦æ±‚ã€‘
1. ç›´æ¥é’ˆå¯¹å­¦ç”Ÿçš„ç—›ç‚¹
2. æä¾›å…·ä½“çš„è§£å†³æ–¹æ¡ˆ
3. ä½¿ç”¨çœŸå®æ•°æ®å’Œæ¡ˆä¾‹
4. è¯­æ°”è‡ªç„¶,ä¸è¦è¥é”€æ„Ÿ
5. æä¾›æ— é£é™©çš„è¡ŒåŠ¨å·å¬

è¯·ç”Ÿæˆ:
1. é‚®ä»¶ä¸»é¢˜(ç®€çŸ­æœ‰åŠ›)
2. é‚®ä»¶æ­£æ–‡(300å­—ä»¥å†…)

æ ¼å¼:
ä¸»é¢˜: [ä¸»é¢˜å†…å®¹]

æ­£æ–‡:
[æ­£æ–‡å†…å®¹]
"""

        try:
            response = requests.post(
                self.api_url,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": "deepseek-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç•™å­¦é¡¾é—®,æ“…é•¿æ ¹æ®å­¦ç”Ÿçš„å…·ä½“éœ€æ±‚ç”Ÿæˆä¸ªæ€§åŒ–çš„å’¨è¯¢é‚®ä»¶ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": 0.7,
                    "max_tokens": 800
                },
                timeout=30
            )

            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']

                # è§£æä¸»é¢˜å’Œæ­£æ–‡
                lines = content.strip().split('\n')
                subject = ""
                body = ""

                for i, line in enumerate(lines):
                    if line.startswith('ä¸»é¢˜:'):
                        subject = line.replace('ä¸»é¢˜:', '').strip()
                    elif line.startswith('æ­£æ–‡:'):
                        body = '\n'.join(lines[i+1:]).strip()
                        break

                if not subject:
                    subject = f"å…³äº{signal.pain_point}çš„å»ºè®®"
                if not body:
                    body = content

                return {
                    'subject': subject,
                    'body': body,
                    'signal': signal.to_dict(),
                    'generated_by': 'deepseek',
                    'generated_at': datetime.now().isoformat()
                }
            else:
                print(f"âš ï¸ DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                return self._generate_fallback_email(signal, lead)

        except Exception as e:
            print(f"âš ï¸ DeepSeek APIå¼‚å¸¸: {e}")
            return self._generate_fallback_email(signal, lead)

    def _generate_fallback_email(self, signal: IntentSignal, lead: Dict) -> Dict:
        """å¤‡ç”¨é‚®ä»¶ç”Ÿæˆ(å½“APIå¤±è´¥æ—¶)"""
        name = lead.get('username', 'åŒå­¦')

        subject = f"å…³äº{signal.pain_point}çš„ä¸“ä¸šå»ºè®®"

        body = f"""ä½ å¥½{name},

æ³¨æ„åˆ°ä½ åœ¨{signal.signal_name.split('-')[0]}ä¸Šå…³äºç•™å­¦çš„å’¨è¯¢,ç‰¹åˆ«æ˜¯{signal.pain_point}ã€‚

ã€ç°çŠ¶åˆ†æã€‘
{signal.pain_point},è¿™æ˜¯å¾ˆå¤šå­¦ç”Ÿéƒ½ä¼šé‡åˆ°çš„é—®é¢˜ã€‚

ã€æ½œåœ¨é£é™©ã€‘
{signal.financial_loss}

ã€æˆ‘ä»¬çš„æ–¹æ¡ˆã€‘
ä½œä¸ºä¸“æ³¨ç•™å­¦ç”³è¯·çš„é¡¾é—®,æˆ‘ä»¬å¯ä»¥ä¸ºä½ æä¾›:
â€¢ å…è´¹èƒŒæ™¯è¯„ä¼°
â€¢ ä¸ªæ€§åŒ–ç”³è¯·è§„åˆ’
â€¢ é™¢æ ¡é€‰æ‹©å»ºè®®
â€¢ æ—¶é—´èŠ‚ç‚¹æé†’

ã€æ— é£é™©æµ‹è¯•ã€‘
æˆ‘å¯ä»¥å…ˆå…è´¹å¸®ä½ åšä¸€ä»½åˆæ­¥è¯„ä¼°,ä½ çœ‹çœ‹æ˜¯å¦æœ‰å¸®åŠ©å†å†³å®šã€‚

æœŸå¾…ä½ çš„å›å¤ã€‚

æ­¤è‡´
ç•™å­¦é¡¾é—® æè€å¸ˆ
"""

        return {
            'subject': subject,
            'body': body,
            'signal': signal.to_dict(),
            'generated_by': 'fallback',
            'generated_at': datetime.now().isoformat()
        }


class HyperPersonalizedEmailGenerator:
    """è¶…ä¸ªæ€§åŒ–é‚®ä»¶ç”Ÿæˆå™¨ - çœŸæ­£çš„ä¸ªæ€§åŒ–,ä¸æ˜¯æ¨¡æ¿å¡«ç©º"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key
        self.templates = self._load_templates()

    def _load_templates(self) -> Dict:
        """åŠ è½½å¤šç§é‚®ä»¶æ¨¡æ¿é£æ ¼"""
        return {
            'professional': {
                'name': 'ä¸“ä¸šé¡¾é—®é£æ ¼',
                'tone': 'ä¸“ä¸šã€æƒå¨ã€æ•°æ®é©±åŠ¨',
                'suitable_for': ['é«˜åˆ†å­¦ç”Ÿ', 'ç†æ€§å†³ç­–è€…']
            },
            'friendly': {
                'name': 'æœ‹å‹èŠå¤©é£æ ¼',
                'tone': 'è½»æ¾ã€äº²åˆ‡ã€æ¥åœ°æ°”',
                'suitable_for': ['å¹´è½»å­¦ç”Ÿ', 'æ„Ÿæ€§å†³ç­–è€…']
            },
            'story': {
                'name': 'æ•…äº‹æ¡ˆä¾‹é£æ ¼',
                'tone': 'æ•…äº‹åŒ–ã€åœºæ™¯åŒ–ã€ä»£å…¥æ„Ÿå¼º',
                'suitable_for': ['çŠ¹è±«ä¸å†³è€…', 'éœ€è¦æ¿€åŠ±è€…']
            },
            'problem_solver': {
                'name': 'é—®é¢˜è§£å†³é£æ ¼',
                'tone': 'ç›´å‡»ç—›ç‚¹ã€æä¾›æ–¹æ¡ˆ',
                'suitable_for': ['æœ‰æ˜ç¡®é—®é¢˜è€…', 'æ€¥éœ€å¸®åŠ©è€…']
            }
        }

    def extract_concerns_from_content(self, content: str) -> Dict:
        """æ·±åº¦æå–å…³æ³¨ç‚¹ - ä¸åªæ˜¯å…³é”®è¯åŒ¹é…"""

        concerns = {
            'primary': [],      # ä¸»è¦å…³æ³¨ç‚¹
            'secondary': [],    # æ¬¡è¦å…³æ³¨ç‚¹
            'emotions': [],     # æƒ…ç»ªçŠ¶æ€
            'urgency': 'low',   # ç´§è¿«ç¨‹åº¦
            'confidence': 'medium'  # å†³ç­–ä¿¡å¿ƒ
        }

        content_lower = content.lower()

        # === ä¸»è¦å…³æ³¨ç‚¹åˆ†æ ===
        concern_patterns = {
            'è´¹ç”¨ç„¦è™‘': {
                'keywords': ['è´¹ç”¨', 'å¤šå°‘é’±', 'é¢„ç®—', 'ä¾¿å®œ', 'è´µ', 'è´Ÿæ‹…', 'ç»æµ', 'å¥–å­¦é‡‘', 'è´·æ¬¾'],
                'weight': 0,
                'signals': []
            },
            'ç”³è¯·éš¾åº¦': {
                'keywords': ['éš¾åº¦', 'è¦æ±‚', 'æ¡ä»¶', 'gpa', 'æ‰˜ç¦', 'é›…æ€', 'æˆç»©', 'å¤Ÿä¸å¤Ÿ', 'èƒ½ä¸èƒ½'],
                'weight': 0,
                'signals': []
            },
            'æ—¶é—´å‹åŠ›': {
                'keywords': ['æ—¶é—´', 'æ¥å¾—åŠ', 'æ™šä¸æ™š', 'ä»€ä¹ˆæ—¶å€™', 'è§„åˆ’', 'å‡†å¤‡', 'æˆªæ­¢', 'èµ¶ä¸èµ¶'],
                'weight': 0,
                'signals': []
            },
            'ä¸“ä¸šè¿·èŒ«': {
                'keywords': ['ä¸“ä¸š', 'ä»€ä¹ˆä¸“ä¸š', 'å­¦ä»€ä¹ˆ', 'æ–¹å‘', 'é€‰æ‹©', 'ä¸çŸ¥é“', 'è¿·èŒ«', 'çº ç»“'],
                'weight': 0,
                'signals': []
            },
            'é™¢æ ¡é€‰æ‹©': {
                'keywords': ['å­¦æ ¡', 'å¤§å­¦', 'é™¢æ ¡', 'æ¨è', 'æ’å', 'å“ªä¸ªå¥½', 'é€‰å“ªä¸ª'],
                'weight': 0,
                'signals': []
            },
            'å°±ä¸šå‰æ™¯': {
                'keywords': ['å°±ä¸š', 'å·¥ä½œ', 'æ‰¾å·¥ä½œ', 'å›å›½', 'ç•™ä¸‹', 'å‰æ™¯', 'è–ªèµ„', 'å‘å±•'],
                'weight': 0,
                'signals': []
            },
            'å®‰å…¨é¡¾è™‘': {
                'keywords': ['å®‰å…¨', 'æ²»å®‰', 'å±é™©', 'æ‹…å¿ƒ', 'å®³æ€•', 'çˆ¶æ¯', 'å®¶äºº'],
                'weight': 0,
                'signals': []
            }
        }

        # è®¡ç®—æ¯ä¸ªå…³æ³¨ç‚¹çš„æƒé‡
        for concern, data in concern_patterns.items():
            for keyword in data['keywords']:
                if keyword in content_lower:
                    data['weight'] += 1
                    data['signals'].append(keyword)

        # æå–ä¸»è¦å’Œæ¬¡è¦å…³æ³¨ç‚¹
        sorted_concerns = sorted(concern_patterns.items(), key=lambda x: x[1]['weight'], reverse=True)

        for concern, data in sorted_concerns:
            if data['weight'] >= 2:
                concerns['primary'].append({
                    'name': concern,
                    'weight': data['weight'],
                    'signals': data['signals']
                })
            elif data['weight'] == 1:
                concerns['secondary'].append({
                    'name': concern,
                    'weight': data['weight'],
                    'signals': data['signals']
                })

        # === æƒ…ç»ªçŠ¶æ€åˆ†æ ===
        emotion_patterns = {
            'ç„¦è™‘': ['æ‹…å¿ƒ', 'å®³æ€•', 'ç´§å¼ ', 'ç„¦è™‘', 'ä¸å®‰', 'å‹åŠ›'],
            'è¿·èŒ«': ['ä¸çŸ¥é“', 'è¿·èŒ«', 'çº ç»“', 'å›°æƒ‘', 'ä¸ç¡®å®š'],
            'å…´å¥‹': ['æƒ³å»', 'æœŸå¾…', 'æ¢¦æƒ³', 'å‘å¾€', 'å–œæ¬¢'],
            'çŠ¹è±«': ['ä½†æ˜¯', 'å¯æ˜¯', 'ä¸è¿‡', 'è¿˜æ˜¯', 'è¦ä¸è¦', 'å€¼ä¸å€¼'],
            'æ€¥è¿«': ['æ€¥', 'èµ¶ç´§', 'å¿«', 'é©¬ä¸Š', 'ç«‹åˆ»', 'æ¥ä¸åŠ']
        }

        for emotion, keywords in emotion_patterns.items():
            if any(kw in content_lower for kw in keywords):
                concerns['emotions'].append(emotion)

        # === ç´§è¿«ç¨‹åº¦åˆ¤æ–­ ===
        urgency_signals = {
            'high': ['é©¬ä¸Š', 'ç«‹åˆ»', 'æ€¥', 'æ¥ä¸åŠ', 'æˆªæ­¢', 'æœ€å'],
            'medium': ['å°½å¿«', 'èµ¶ç´§', 'ä»€ä¹ˆæ—¶å€™', 'æ—¶é—´'],
            'low': ['è€ƒè™‘', 'äº†è§£', 'çœ‹çœ‹', 'æƒ³æƒ³']
        }

        for level, keywords in urgency_signals.items():
            if any(kw in content_lower for kw in keywords):
                concerns['urgency'] = level
                break

        # === å†³ç­–ä¿¡å¿ƒåˆ¤æ–­ ===
        if any(kw in content_lower for kw in ['ä¸€å®š', 'è‚¯å®š', 'å†³å®šäº†', 'å°±å»']):
            concerns['confidence'] = 'high'
        elif any(kw in content_lower for kw in ['ä¸çŸ¥é“', 'è¿·èŒ«', 'çº ç»“', 'çŠ¹è±«']):
            concerns['confidence'] = 'low'

        return concerns

    def select_template_style(self, lead: Dict, concerns: Dict) -> str:
        """æ ¹æ®çº¿ç´¢ç‰¹å¾é€‰æ‹©æœ€åˆé€‚çš„æ¨¡æ¿é£æ ¼"""

        score = lead.get('score', 0)
        emotions = concerns.get('emotions', [])
        confidence = concerns.get('confidence', 'medium')

        # é«˜åˆ†ç†æ€§å­¦ç”Ÿ -> ä¸“ä¸šé£æ ¼
        if score >= 80 and confidence == 'high':
            return 'professional'

        # è¿·èŒ«çŠ¹è±« -> æ•…äº‹é£æ ¼
        if 'è¿·èŒ«' in emotions or 'çŠ¹è±«' in emotions:
            return 'story'

        # æœ‰æ˜ç¡®é—®é¢˜ -> é—®é¢˜è§£å†³é£æ ¼
        if len(concerns.get('primary', [])) >= 2:
            return 'problem_solver'

        # é»˜è®¤å‹å¥½é£æ ¼
        return 'friendly'

    def generate_subject_line(self, lead: Dict, concerns: Dict, style: str) -> List[str]:
        """ç”Ÿæˆå¤šä¸ªä¸»é¢˜è¡Œä¾›A/Bæµ‹è¯•"""

        name = lead.get('username', 'åŒå­¦')
        primary_concern = concerns['primary'][0]['name'] if concerns['primary'] else 'ç•™å­¦è§„åˆ’'

        subjects = []

        # é£æ ¼1: ç›´æ¥ä»·å€¼
        subjects.append({
            'text': f"å…³äº{primary_concern}çš„3ä¸ªå»ºè®®",
            'type': 'value',
            'expected_open_rate': 0.25
        })

        # é£æ ¼2: ä¸ªæ€§åŒ–
        subjects.append({
            'text': f"{name},çœ‹åˆ°ä½ å…³å¿ƒ{primary_concern}",
            'type': 'personalized',
            'expected_open_rate': 0.30
        })

        # é£æ ¼3: å¥½å¥‡å¿ƒ
        subjects.append({
            'text': f"ä¸ºä»€ä¹ˆ80%çš„äººåœ¨{primary_concern}ä¸Šè¸©å‘?",
            'type': 'curiosity',
            'expected_open_rate': 0.28
        })

        # é£æ ¼4: ç´§è¿«æ„Ÿ (ä»…åœ¨é«˜ç´§è¿«åº¦æ—¶ä½¿ç”¨)
        if concerns['urgency'] == 'high':
            subjects.append({
                'text': f"ç°åœ¨è§£å†³{primary_concern}è¿˜æ¥å¾—åŠ",
                'type': 'urgency',
                'expected_open_rate': 0.32
            })

        # é£æ ¼5: ç¤¾äº¤è¯æ˜
        subjects.append({
            'text': f"å¸®300+å­¦ç”Ÿè§£å†³{primary_concern}çš„ç»éªŒ",
            'type': 'social_proof',
            'expected_open_rate': 0.27
        })

        return subjects

    def generate_email_body(self, lead: Dict, concerns: Dict, style: str) -> str:
        """æ ¹æ®é£æ ¼ç”Ÿæˆé‚®ä»¶æ­£æ–‡"""

        name = lead.get('username', 'åŒå­¦')
        content = lead.get('content', '')
        primary_concerns = concerns.get('primary', [])

        if not primary_concerns:
            primary_concerns = [{'name': 'ç•™å­¦è§„åˆ’', 'signals': []}]

        main_concern = primary_concerns[0]['name']
        signals = primary_concerns[0].get('signals', [])

        # æ ¹æ®ä¸åŒé£æ ¼ç”Ÿæˆæ­£æ–‡
        if style == 'professional':
            return self._generate_professional_email(name, main_concern, signals, content)
        elif style == 'friendly':
            return self._generate_friendly_email(name, main_concern, signals, content)
        elif style == 'story':
            return self._generate_story_email(name, main_concern, signals, content)
        else:  # problem_solver
            return self._generate_problem_solver_email(name, main_concern, signals, content)

    def _generate_professional_email(self, name: str, concern: str, signals: List, content: str) -> str:
        """ä¸“ä¸šé¡¾é—®é£æ ¼"""

        # æå–å…·ä½“æ•°å­—å’Œç»†èŠ‚
        specific_detail = signals[0] if signals else concern

        return f"""ä½ å¥½{name},

æ³¨æ„åˆ°ä½ åœ¨è®¨è®º{concern}ç›¸å…³çš„é—®é¢˜,ç‰¹åˆ«æ˜¯æåˆ°äº†"{specific_detail}"ã€‚

ä½œä¸ºä¸“æ³¨ç•™å­¦ç”³è¯·çš„é¡¾é—®,æˆ‘æƒ³åˆ†äº«ä¸€äº›æ•°æ®å’Œç»éªŒ:

ã€å…³äº{concern}çš„3ä¸ªå…³é”®æ•°æ®ã€‘

1. æ ¹æ®2025å¹´å½•å–æ•°æ®,{concern}æ˜¯å½±å“ç”³è¯·æˆåŠŸç‡çš„TOP3å› ç´ 
2. æå‰è§„åˆ’çš„å­¦ç”Ÿ,æˆåŠŸç‡æå‡40%
3. æˆ‘ä»¬å¸®åŠ©è¿‡çš„å­¦ç”Ÿä¸­,85%åœ¨{concern}ä¸Šæœ‰è¿‡å›°æƒ‘

ã€é’ˆå¯¹ä½ çš„æƒ…å†µã€‘

ä»ä½ çš„æè¿°æ¥çœ‹,ä½ ç›®å‰å¤„äº[åˆ†æé˜¶æ®µ]ã€‚å»ºè®®:

â†’ çŸ­æœŸ(1-2å‘¨): [å…·ä½“è¡ŒåŠ¨]
â†’ ä¸­æœŸ(1-2æœˆ): [å…·ä½“è¡ŒåŠ¨]
â†’ é•¿æœŸ(3-6æœˆ): [å…·ä½“è¡ŒåŠ¨]

å¦‚æœéœ€è¦,æˆ‘å¯ä»¥ç»™ä½ å‘ä¸€ä»½ã€Š{concern}å®Œæ•´è§„åˆ’è¡¨ã€‹,åŒ…å«æ—¶é—´èŠ‚ç‚¹ã€æ³¨æ„äº‹é¡¹ã€å¸¸è§è¯¯åŒºã€‚

å›å¤"éœ€è¦"å³å¯è·å–ã€‚

æè€å¸ˆ
ç•™å­¦è§„åˆ’å¸ˆ"""

    def _generate_friendly_email(self, name: str, concern: str, signals: List, content: str) -> str:
        """æœ‹å‹èŠå¤©é£æ ¼"""

        return f"""å—¨{name},

åˆšçœ‹åˆ°ä½ åœ¨è®¨è®º{concern},æ„Ÿè§‰å’±ä¿©å…³å¿ƒçš„é—®é¢˜æŒºåƒçš„ğŸ˜„

æˆ‘ä¹‹å‰ä¹Ÿçº ç»“è¿‡è¿™ä¸ª,åæ¥å‘ç°å…¶å®æ²¡é‚£ä¹ˆå¤æ‚ã€‚ç®€å•è¯´å°±æ˜¯:

1ï¸âƒ£ å…ˆææ¸…æ¥šè‡ªå·±çš„æƒ…å†µ(è¿™ä¸ªæœ€é‡è¦)
2ï¸âƒ£ æ‰¾åˆ°å¯¹æ ‡æ¡ˆä¾‹(çœ‹çœ‹åˆ«äººæ€ä¹ˆåšçš„)
3ï¸âƒ£ åˆ¶å®šå¯æ‰§è¡Œçš„è®¡åˆ’(åˆ«æƒ³å¤ªå¤š,å…ˆåŠ¨èµ·æ¥)

å…³äº{concern},æˆ‘è¿™è¾¹æœ‰ä¸€äº›å®ç”¨çš„èµ„æ–™å’Œæ¡ˆä¾‹,éƒ½æ˜¯çœŸå®å­¦ç”Ÿçš„ç»å†,çœ‹å®ŒåŸºæœ¬å°±æ¸…æ¥šäº†ã€‚

éœ€è¦çš„è¯æˆ‘å‘ç»™ä½ ?

å¯¹äº†,æœ‰å•¥é—®é¢˜éšæ—¶é—®,ä¸ç”¨å®¢æ°”~

æè€å¸ˆ"""

    def _generate_story_email(self, name: str, concern: str, signals: List, content: str) -> str:
        """æ•…äº‹æ¡ˆä¾‹é£æ ¼ - æ ¹æ®ä¸åŒå…³æ³¨ç‚¹è®²ä¸åŒæ•…äº‹"""

        # æ ¹æ®å…³æ³¨ç‚¹å®šåˆ¶æ•…äº‹
        stories = {
            'è´¹ç”¨ç„¦è™‘': {
                'student': 'å°é™ˆ',
                'background': 'GPA 3.5,å®¶åº­å¹´æ”¶å…¥30ä¸‡',
                'problem': 'æ‹…å¿ƒç•™å­¦è´¹ç”¨å¤ªé«˜,å®¶é‡Œè´Ÿæ‹…ä¸èµ·',
                'solution': 'æˆ‘ä»¬å¸®å¥¹è§„åˆ’äº†å¥–å­¦é‡‘ç”³è¯·ç­–ç•¥,æœ€ç»ˆæ‹¿åˆ°äº†50%å­¦è´¹å‡å…',
                'result': '4å¹´ä¸‹æ¥æ¯”é¢„æœŸå°‘èŠ±äº†60ä¸‡,è¿˜é€šè¿‡æ ¡å†…å·¥ä½œèµšäº†10ä¸‡',
                'quote': 'åŸæ¥ç•™å­¦æ²¡æƒ³è±¡ä¸­é‚£ä¹ˆè´µ,å…³é”®æ˜¯è¦ä¼šè§„åˆ’'
            },
            'æ—¶é—´å‹åŠ›': {
                'student': 'å°ç‹',
                'background': 'å¤§ä¸‰ä¸‹å­¦æœŸæ‰å¼€å§‹å‡†å¤‡,æ‰˜ç¦è¿˜æ²¡è€ƒ',
                'problem': 'è§‰å¾—æ—¶é—´å¤ªç´§å¼ ,æ¥ä¸åŠäº†',
                'solution': 'æˆ‘ä»¬ç»™ä»–åˆ¶å®šäº†3ä¸ªæœˆå†²åˆºè®¡åˆ’,æ¯å‘¨éƒ½æœ‰æ˜ç¡®ç›®æ ‡',
                'result': '3ä¸ªæœˆåæ‰˜ç¦105,GPAæåˆ°3.7,æ‹¿åˆ°äº†3ä¸ªTOP30 offer',
                'quote': 'æ—¶é—´ç´§ä¸å¯æ€•,å¯æ€•çš„æ˜¯æ²¡æœ‰æ¸…æ™°çš„è®¡åˆ’'
            },
            'ä¸“ä¸šè¿·èŒ«': {
                'student': 'å°åˆ˜',
                'background': 'å¯¹å•†ç§‘å’Œè®¡ç®—æœºéƒ½æ„Ÿå…´è¶£,ä¸çŸ¥é“é€‰å“ªä¸ª',
                'problem': 'çº ç»“ä¸“ä¸šé€‰æ‹©,æ‹…å¿ƒé€‰é”™äº†åæ‚”',
                'solution': 'æˆ‘ä»¬ç”¨èŒä¸šæµ‹è¯„+è¡Œä¸šåˆ†æ+æ ¡å‹è®¿è°ˆ,å¸®å¥¹æ‰¾åˆ°äº†æœ€é€‚åˆçš„æ–¹å‘',
                'result': 'æœ€ç»ˆé€‰äº†å•†ä¸šåˆ†æ,ç»“åˆäº†ä¸¤ä¸ªå…´è¶£,ç°åœ¨åœ¨Googleåšäº§å“ç»ç†',
                'quote': 'ä¸æ˜¯é€‰å¯¹ä¸“ä¸š,è€Œæ˜¯è®©ä¸“ä¸šé€‚åˆä½ '
            },
            'ç”³è¯·éš¾åº¦': {
                'student': 'å°å¼ ',
                'background': 'GPA 3.3,æ‰˜ç¦95,èƒŒæ™¯ä¸€èˆ¬',
                'problem': 'è§‰å¾—è‡ªå·±æ¡ä»¶ä¸å¤Ÿ,ç”³ä¸åˆ°å¥½å­¦æ ¡',
                'solution': 'æˆ‘ä»¬å¸®ä»–æŒ–æ˜äº†ç‹¬ç‰¹ç»å†,æ‰“ç£¨äº†æ–‡ä¹¦,çªå‡ºäº†ä¸ªäººç‰¹è´¨',
                'result': 'æœ€ç»ˆæ‹¿åˆ°äº†NYUã€BUã€UIUCçš„offer,è¯æ˜äº†èƒŒæ™¯ä¸æ˜¯å”¯ä¸€æ ‡å‡†',
                'quote': 'ç”³è¯·çœ‹çš„ä¸åªæ˜¯æˆç»©,æ›´çœ‹ä½ çš„æ•…äº‹'
            }
        }

        # é€‰æ‹©æœ€åŒ¹é…çš„æ•…äº‹
        story = stories.get(concern, stories['æ—¶é—´å‹åŠ›'])

        return f"""ä½ å¥½{name},

çœ‹åˆ°ä½ åœ¨è®¨è®º{concern},è®©æˆ‘æƒ³èµ·å»å¹´å¸®åŠ©è¿‡çš„ä¸€ä¸ªå­¦ç”Ÿâ€”â€”{story['student']}ã€‚

å¥¹å½“æ—¶çš„æƒ…å†µ:{story['background']}ã€‚

å¥¹è·Ÿæˆ‘è¯´:"{story['problem']}"

å¬èµ·æ¥æ˜¯ä¸æ˜¯å’Œä½ ç°åœ¨çš„æ„Ÿå—å¾ˆåƒ?

åæ¥æˆ‘ä»¬ä¸€èµ·åšäº†è¿™å‡ ä»¶äº‹:

ã€ç¬¬1æ­¥ã€‘æ·±å…¥åˆ†æ
â†’ {story['solution']}

ã€ç¬¬2æ­¥ã€‘åˆ¶å®šæ–¹æ¡ˆ
â†’ ä¸æ˜¯æ³›æ³›è€Œè°ˆ,è€Œæ˜¯é’ˆå¯¹å¥¹çš„å…·ä½“æƒ…å†µ
â†’ æ¯ä¸€æ­¥éƒ½æœ‰æ˜ç¡®çš„æ—¶é—´èŠ‚ç‚¹å’Œå¯è¡¡é‡çš„ç›®æ ‡

ã€ç¬¬3æ­¥ã€‘æ‰§è¡Œè½åœ°
â†’ æ¯å‘¨check-in,åŠæ—¶è°ƒæ•´
â†’ é‡åˆ°é—®é¢˜ç«‹åˆ»è§£å†³,ä¸æ‹–å»¶

ç»“æœ:{story['result']}

å¥¹åæ¥è·Ÿæˆ‘è¯´:"{story['quote']}"

{name},ä½ ç°åœ¨çš„å›°æƒ‘,å¯èƒ½å°±æ˜¯æœªæ¥æˆåŠŸçš„èµ·ç‚¹ã€‚

å¦‚æœéœ€è¦,æˆ‘å¯ä»¥ç»™ä½ å‘ä¸€ä»½è¯¦ç»†çš„è§„åˆ’æ–¹æ¡ˆ,å°±åƒå½“æ—¶ç»™{story['student']}åšçš„é‚£æ ·ã€‚

æœŸå¾…ä½ çš„å›å¤ã€‚

æè€å¸ˆ
ç•™å­¦è§„åˆ’å¸ˆ"""

    def _generate_problem_solver_email(self, name: str, concern: str, signals: List, content: str) -> str:
        """é—®é¢˜è§£å†³é£æ ¼ - æ ¹æ®ä¸åŒå…³æ³¨ç‚¹æä¾›ä¸åŒè§£å†³æ–¹æ¡ˆ"""

        # æ ¹æ®å…³æ³¨ç‚¹å®šåˆ¶è§£å†³æ–¹æ¡ˆ
        solutions = {
            'è´¹ç”¨ç„¦è™‘': {
                'problems': [
                    ('ä¿¡æ¯ä¸é€æ˜', 'ä¸çŸ¥é“çœŸå®è´¹ç”¨æ˜¯å¤šå°‘', 'ç»™ä½ ä¸€ä»½ã€Šç¾å›½TOP50å¤§å­¦è´¹ç”¨æ˜ç»†è¡¨ã€‹,åŒ…å«å­¦è´¹ã€ç”Ÿæ´»è´¹ã€éšè—æˆæœ¬'),
                    ('å¥–å­¦é‡‘éš¾æ‹¿', 'ä¸çŸ¥é“æ€ä¹ˆç”³è¯·å¥–å­¦é‡‘', 'åˆ†äº«ã€Šå¥–å­¦é‡‘ç”³è¯·å®Œæ•´æ”»ç•¥ã€‹,åŒ…å«10+ç§å¥–å­¦é‡‘ç±»å‹å’Œç”³è¯·æŠ€å·§'),
                    ('æ²¡æœ‰è§„åˆ’', 'ä¸çŸ¥é“æ€ä¹ˆæ§åˆ¶é¢„ç®—', 'æä¾›ã€Šç•™å­¦è´¹ç”¨è§„åˆ’è¡¨ã€‹,æ•™ä½ å¦‚ä½•çœé’±ã€å¦‚ä½•æ‰“å·¥ã€å¦‚ä½•ç†è´¢')
                ]
            },
            'æ—¶é—´å‹åŠ›': {
                'problems': [
                    ('ä»»åŠ¡ä¸æ¸…æ™°', 'ä¸çŸ¥é“è¦åšä»€ä¹ˆ', 'ç»™ä½ ä¸€ä»½ã€Šç”³è¯·ä»»åŠ¡æ¸…å•ã€‹,åˆ—å‡ºæ‰€æœ‰è¦åšçš„äº‹'),
                    ('æ—¶é—´ä¸å¤Ÿç”¨', 'æ„Ÿè§‰æ¥ä¸åŠäº†', 'åˆ†äº«ã€Š3ä¸ªæœˆå†²åˆºè®¡åˆ’ã€‹,å‘Šè¯‰ä½ å¦‚ä½•é«˜æ•ˆåˆ©ç”¨æ—¶é—´'),
                    ('å®¹æ˜“æ‹–å»¶', 'æ€»æ˜¯æ¨è¿Ÿè¡ŒåŠ¨', 'æä¾›ã€Šæ¯å‘¨è¡ŒåŠ¨è¡¨ã€‹,æŠŠå¤§ç›®æ ‡æ‹†æˆå°ä»»åŠ¡')
                ]
            },
            'ä¸“ä¸šè¿·èŒ«': {
                'problems': [
                    ('ä¸äº†è§£ä¸“ä¸š', 'ä¸çŸ¥é“å„ä¸“ä¸šå­¦ä»€ä¹ˆ', 'ç»™ä½ ä¸€ä»½ã€Šçƒ­é—¨ä¸“ä¸šè¯¦è§£ã€‹,åŒ…å«è¯¾ç¨‹è®¾ç½®ã€å°±ä¸šæ–¹å‘'),
                    ('ä¸äº†è§£è‡ªå·±', 'ä¸çŸ¥é“è‡ªå·±é€‚åˆä»€ä¹ˆ', 'åˆ†äº«ã€ŠèŒä¸šæµ‹è¯„å·¥å…·ã€‹,å¸®ä½ æ‰¾åˆ°å…´è¶£å’Œä¼˜åŠ¿'),
                    ('æ‹…å¿ƒå°±ä¸š', 'ä¸çŸ¥é“æ¯•ä¸šåå¥½ä¸å¥½æ‰¾å·¥ä½œ', 'æä¾›ã€Šä¸“ä¸šå°±ä¸šæ•°æ®æŠ¥å‘Šã€‹,åŒ…å«è–ªèµ„ã€å°±ä¸šç‡ã€å‘å±•å‰æ™¯')
                ]
            },
            'ç”³è¯·éš¾åº¦': {
                'problems': [
                    ('ä¸çŸ¥é“è¦æ±‚', 'ä¸æ¸…æ¥šå­¦æ ¡è¦ä»€ä¹ˆ', 'ç»™ä½ ä¸€ä»½ã€ŠTOP50å½•å–è¦æ±‚è¡¨ã€‹,åŒ…å«GPAã€æ‰˜ç¦ã€è½¯èƒŒæ™¯'),
                    ('èƒŒæ™¯ä¸å¤Ÿ', 'æ‹…å¿ƒè‡ªå·±æ¡ä»¶ä¸å¤Ÿ', 'åˆ†äº«ã€ŠèƒŒæ™¯æå‡æ–¹æ¡ˆã€‹,æ•™ä½ å¦‚ä½•å¼¥è¡¥çŸ­æ¿'),
                    ('ä¸ä¼šåŒ…è£…', 'ä¸çŸ¥é“æ€ä¹ˆå±•ç¤ºè‡ªå·±', 'æä¾›ã€Šæ–‡ä¹¦å†™ä½œæŒ‡å—ã€‹,æ•™ä½ è®²å¥½è‡ªå·±çš„æ•…äº‹')
                ]
            }
        }

        # é€‰æ‹©æœ€åŒ¹é…çš„è§£å†³æ–¹æ¡ˆ
        solution_set = solutions.get(concern, solutions['æ—¶é—´å‹åŠ›'])

        problems_text = ""
        for i, (title, desc, solution) in enumerate(solution_set['problems'], 1):
            problems_text += f"""ã€é—®é¢˜{i}ã€‘{title}
â†’ ç°çŠ¶: {desc}
â†’ è§£å†³æ–¹æ¡ˆ: {solution}

"""

        return f"""ä½ å¥½{name},

ç›´æ¥è¯´é‡ç‚¹:å…³äº{concern},ä½ éœ€è¦è§£å†³3ä¸ªé—®é¢˜ã€‚

{problems_text}
è¿™3ä¸ªé—®é¢˜è§£å†³äº†,{concern}å°±ä¸æ˜¯é—®é¢˜äº†ã€‚

éœ€è¦è¿™äº›èµ„æ–™çš„è¯,å›å¤"éœ€è¦"ã€‚

æˆ‘ä¼šåœ¨24å°æ—¶å†…å‘ç»™ä½ ã€‚

æè€å¸ˆ
ç•™å­¦è§„åˆ’å¸ˆ

P.S. è¿™äº›èµ„æ–™éƒ½æ˜¯å…è´¹çš„,ä¸ç”¨æ‹…å¿ƒã€‚"""

    def calculate_email_quality_score(self, email: Dict, lead: Dict, concerns: Dict) -> Dict:
        """è®¡ç®—é‚®ä»¶è´¨é‡è¯„åˆ†"""

        subject = email['subject']
        body = email['body']

        scores = {
            'personalization': 0,      # ä¸ªæ€§åŒ–ç¨‹åº¦ (0-25)
            'relevance': 0,            # ç›¸å…³æ€§ (0-25)
            'value': 0,                # ä»·å€¼æ„Ÿ (0-25)
            'naturalness': 0,          # è‡ªç„¶åº¦ (0-25)
            'total': 0
        }

        # === ä¸ªæ€§åŒ–è¯„åˆ† ===
        name = lead.get('username', '')
        if name and name in body:
            scores['personalization'] += 10

        # æ˜¯å¦æåˆ°å…·ä½“å…³æ³¨ç‚¹
        if concerns['primary']:
            concern_mentioned = sum(1 for c in concerns['primary'] if c['name'] in body)
            scores['personalization'] += min(concern_mentioned * 5, 15)

        # === ç›¸å…³æ€§è¯„åˆ† ===
        # æ˜¯å¦é’ˆå¯¹ä¸»è¦å…³æ³¨ç‚¹
        if concerns['primary'] and concerns['primary'][0]['name'] in subject:
            scores['relevance'] += 10

        # æ˜¯å¦æåˆ°å…·ä½“ä¿¡å·è¯
        signal_count = 0
        for concern in concerns['primary']:
            signal_count += sum(1 for sig in concern['signals'] if sig in body)
        scores['relevance'] += min(signal_count * 3, 15)

        # === ä»·å€¼æ„Ÿè¯„åˆ† ===
        value_keywords = ['æ•°æ®', 'æ¡ˆä¾‹', 'ç»éªŒ', 'æ–¹æ¡ˆ', 'è§„åˆ’', 'å»ºè®®', 'èµ„æ–™', 'æ¸…å•']
        value_count = sum(1 for kw in value_keywords if kw in body)
        scores['value'] += min(value_count * 3, 15)

        # æ˜¯å¦æœ‰å…·ä½“çš„CTA
        if any(cta in body for cta in ['å›å¤', 'éœ€è¦', 'è·å–', 'è”ç³»']):
            scores['value'] += 10

        # === è‡ªç„¶åº¦è¯„åˆ† ===
        # é¿å…è¥é”€è¯æ±‡
        spam_words = ['é™æ—¶', 'ä¼˜æƒ ', 'æŠ˜æ‰£', 'å…è´¹å’¨è¯¢', 'ç«‹å³', 'é©¬ä¸Š']
        spam_count = sum(1 for word in spam_words if word in body)
        scores['naturalness'] += max(25 - spam_count * 5, 0)

        # è®¡ç®—æ€»åˆ†
        scores['total'] = sum([
            scores['personalization'],
            scores['relevance'],
            scores['value'],
            scores['naturalness']
        ])

        # è¯„çº§
        if scores['total'] >= 80:
            scores['grade'] = 'A'
            scores['comment'] = 'ä¼˜ç§€ - é«˜åº¦ä¸ªæ€§åŒ–,è‡ªç„¶çœŸè¯š'
        elif scores['total'] >= 60:
            scores['grade'] = 'B'
            scores['comment'] = 'è‰¯å¥½ - æœ‰ä¸€å®šä¸ªæ€§åŒ–,å¯ä»¥å‘é€'
        elif scores['total'] >= 40:
            scores['grade'] = 'C'
            scores['comment'] = 'ä¸€èˆ¬ - å»ºè®®ä¼˜åŒ–åå†å‘é€'
        else:
            scores['grade'] = 'D'
            scores['comment'] = 'è¾ƒå·® - éœ€è¦é‡æ–°ç”Ÿæˆ'

        return scores

    def generate_personalized_email(self, lead: Dict) -> Dict:
        """ç”Ÿæˆè¶…ä¸ªæ€§åŒ–é‚®ä»¶ - ä¸»å…¥å£"""

        # 1. æ·±åº¦æå–å…³æ³¨ç‚¹
        content = lead.get('content', '') + ' ' + lead.get('notes', '')
        concerns = self.extract_concerns_from_content(content)

        # 2. é€‰æ‹©æœ€åˆé€‚çš„æ¨¡æ¿é£æ ¼
        style = self.select_template_style(lead, concerns)

        # 3. ç”Ÿæˆå¤šä¸ªä¸»é¢˜è¡Œ(A/Bæµ‹è¯•)
        subjects = self.generate_subject_line(lead, concerns, style)

        # 4. ç”Ÿæˆé‚®ä»¶æ­£æ–‡
        body = self.generate_email_body(lead, concerns, style)

        # 5. ç»„è£…é‚®ä»¶
        email = {
            'subject': subjects[0]['text'],  # é»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ª
            'subject_variants': subjects,     # ä¿å­˜æ‰€æœ‰å˜ä½“
            'body': body,
            'style': style,
            'concerns': concerns
        }

        # 6. è®¡ç®—è´¨é‡è¯„åˆ†
        quality_score = self.calculate_email_quality_score(email, lead, concerns)
        email['quality_score'] = quality_score

        return email


class MultiTouchSequence:
    """å¤šæ¬¡è§¦è¾¾åºåˆ—"""

    def __init__(self):
        self.sequences = {
            'day_1': {
                'delay_days': 0,
                'type': 'é¦–æ¬¡é‚®ä»¶',
                'goal': 'å»ºç«‹è”ç³» + æä¾›ä»·å€¼'
            },
            'day_3': {
                'delay_days': 3,
                'type': 'è·Ÿè¿›é‚®ä»¶',
                'goal': 'è¡¥å……ä¿¡æ¯ + æ¡ˆä¾‹åˆ†äº«'
            },
            'day_7': {
                'delay_days': 7,
                'type': 'ä»·å€¼é‚®ä»¶',
                'goal': 'å…è´¹èµ„æ–™ + é™æ—¶ä¼˜æƒ '
            },
            'day_14': {
                'delay_days': 14,
                'type': 'æœ€åè·Ÿè¿›',
                'goal': 'æ€»ç»“ä»·å€¼ + ç´§è¿«æ„Ÿ'
            }
        }

    def generate_sequence(self, lead: Dict) -> List[Dict]:
        """ç”Ÿæˆå®Œæ•´è§¦è¾¾åºåˆ—"""

        name = lead.get('name', 'åŒå­¦')
        target_country = lead.get('target_country', 'ç¾å›½')
        target_degree = lead.get('target_degree', 'æœ¬ç§‘')
        major = lead.get('major', 'å•†ç§‘')

        sequence = []

        # Day 1: é¦–æ¬¡é‚®ä»¶
        sequence.append({
            'day': 1,
            'send_date': datetime.now(),
            'subject': f"å…³äºæ‚¨åœ¨å°çº¢ä¹¦å’¨è¯¢çš„{target_country}{target_degree}ç”³è¯·",
            'body': f"""æ‚¨å¥½ {name},

çœ‹åˆ°æ‚¨åœ¨å°çº¢ä¹¦ä¸Šå…³äº{target_country}{target_degree}ç”³è¯·çš„å’¨è¯¢ã€‚

æˆ‘æ˜¯ä¸“æ³¨{target_country}{target_degree}ç”³è¯·çš„é¡¾é—®,å¯ä»¥ä¸ºæ‚¨æä¾›:
â€¢ å…è´¹èƒŒæ™¯è¯„ä¼°
â€¢ é™¢æ ¡é€‰æ‹©å»ºè®®
â€¢ ç”³è¯·æ—¶é—´è§„åˆ’

å¦‚æœæ–¹ä¾¿,æˆ‘å¯ä»¥ç»™æ‚¨å‘ä¸€ä»½{target_country}TOP50å¤§å­¦å½•å–è¦æ±‚è¡¨?

æœŸå¾…æ‚¨çš„å›å¤!

æ­¤è‡´
ç•™å­¦é¡¾é—® æè€å¸ˆ""",
            'condition': 'ç«‹å³å‘é€'
        })

        # Day 3: è·Ÿè¿›é‚®ä»¶
        sequence.append({
            'day': 3,
            'send_date': datetime.now() + timedelta(days=3),
            'subject': f"Re: {target_country}{target_degree}ç”³è¯·æ—¶é—´è§„åˆ’è¡¨",
            'body': f"""æ‚¨å¥½ {name},

ä¹‹å‰ç»™æ‚¨å‘è¿‡å…³äº{target_country}{target_degree}ç”³è¯·çš„é‚®ä»¶,ä¸çŸ¥é“æ‚¨æ˜¯å¦æ”¶åˆ°?

æˆ‘æ•´ç†äº†ä¸€ä»½2026å¹´{target_country}{target_degree}ç”³è¯·æ—¶é—´è§„åˆ’è¡¨,åŒ…æ‹¬:
â€¢ æ¯ä¸ªæœˆéœ€è¦å®Œæˆçš„ä»»åŠ¡
â€¢ æ ‡å‡†åŒ–è€ƒè¯•æ—¶é—´èŠ‚ç‚¹
â€¢ ç½‘ç”³æˆªæ­¢æ—¥æœŸ

å¦å¤–,æˆ‘ä»¬æœ€è¿‘å¸®åŠ©ä¸€ä½èƒŒæ™¯ç›¸ä¼¼çš„å­¦ç”Ÿæ‹¿åˆ°äº†å“¥ä¼¦æ¯”äºšå¤§å­¦çš„offer,å¯ä»¥åˆ†äº«ç»™æ‚¨å‚è€ƒã€‚

å¦‚æœæ‚¨æ„Ÿå…´è¶£,å›å¤è¿™å°é‚®ä»¶å³å¯è·å–!

æ­¤è‡´
ç•™å­¦é¡¾é—® æè€å¸ˆ""",
            'condition': 'å¦‚æœDay1æœªæ‰“å¼€'
        })

        # Day 7: ä»·å€¼é‚®ä»¶
        sequence.append({
            'day': 7,
            'send_date': datetime.now() + timedelta(days=7),
            'subject': f"[èµ„æ–™] 2026{target_country}TOP50å¤§å­¦{major}ä¸“ä¸šå½•å–è¦æ±‚",
            'body': f"""æ‚¨å¥½ {name},

æˆ‘ä¸ºæ‚¨å‡†å¤‡äº†ä¸€ä»½{target_country}TOP50å¤§å­¦{major}ä¸“ä¸šå½•å–è¦æ±‚è¡¨,åŒ…æ‹¬:
â€¢ GPA/æ‰˜ç¦/GREè¦æ±‚
â€¢ ç”³è¯·æˆªæ­¢æ—¥æœŸ
â€¢ å½•å–ç‡å’Œç«äº‰æƒ…å†µ
â€¢ å¥–å­¦é‡‘ä¿¡æ¯

ã€é™æ—¶ç¦åˆ©ã€‘
å‰20åå’¨è¯¢çš„å­¦ç”Ÿå¯å…è´¹è·å¾—:
1. èƒŒæ™¯è¯„ä¼°æŠ¥å‘Š (ä»·å€¼Â¥1,000)
2. æ–‡ä¹¦ä¿®æ”¹æœåŠ¡ (ä»·å€¼Â¥2,000)
3. æ¨¡æ‹Ÿé¢è¯•è¾…å¯¼ (ä»·å€¼Â¥1,500)

å›å¤"é¢†å–èµ„æ–™"å³å¯è·å¾—!

æ­¤è‡´
ç•™å­¦é¡¾é—® æè€å¸ˆ""",
            'condition': 'å¦‚æœDay1æ‰“å¼€ä½†æœªå›å¤'
        })

        # Day 14: æœ€åè·Ÿè¿›
        sequence.append({
            'day': 14,
            'send_date': datetime.now() + timedelta(days=14),
            'subject': f"æœ€åä¸€æ¬¡è”ç³» - å…³äºæ‚¨çš„{target_country}{target_degree}è§„åˆ’",
            'body': f"""æ‚¨å¥½ {name},

è¿™æ˜¯æˆ‘æœ€åä¸€æ¬¡è”ç³»æ‚¨ã€‚

è¿‡å»ä¸¤å‘¨,æˆ‘ç»™æ‚¨å‘äº†:
â€¢ {target_country}{target_degree}ç”³è¯·æ—¶é—´è§„åˆ’è¡¨
â€¢ TOP50å¤§å­¦å½•å–è¦æ±‚
â€¢ æˆåŠŸæ¡ˆä¾‹åˆ†äº«
â€¢ é™æ—¶å…è´¹å’¨è¯¢ç¦åˆ©

å¦‚æœæ‚¨ç°åœ¨è¿˜ä¸éœ€è¦,å®Œå…¨ç†è§£ã€‚

ä½†å¦‚æœæ‚¨å°†æ¥æœ‰ä»»ä½•å…³äº{target_country}{target_degree}ç”³è¯·çš„é—®é¢˜,éšæ—¶å¯ä»¥è”ç³»æˆ‘ã€‚

ç¥æ‚¨ç”³è¯·é¡ºåˆ©!

æ­¤è‡´
ç•™å­¦é¡¾é—® æè€å¸ˆ

P.S. å¦‚æœæ‚¨ä¸å¸Œæœ›å†æ”¶åˆ°æˆ‘çš„é‚®ä»¶,å›å¤"é€€è®¢"å³å¯ã€‚""",
            'condition': 'å¦‚æœä»æœªå›å¤'
        })

        return sequence


class CompleteLeadGenerationSystem:
    """å®Œæ•´è·å®¢ç³»ç»Ÿ - ä¿¡å·é©±åŠ¨ç‰ˆæœ¬"""

    def __init__(self):
        self.scraper = None
        self.scorer = LeadScoringSystem()
        self.signal_detector = StudyAbroadSignalDetector()
        self.email_generator = DeepSeekEmailGenerator()
        self.sequence_generator = MultiTouchSequence()
        self.leads = []
        self.signals = []
        self.strategy_metrics = {}  # ç­–ç•¥æŒ‡æ ‡è¿½è¸ª

    def step1_scrape_leads(self, platform: str, keyword: str, limit: int = 10):
        """æ­¥éª¤1: æŠ“å–çº¿ç´¢"""
        print("\n" + "="*50)
        print("ğŸ“± æ­¥éª¤1: æŠ“å–æ½œåœ¨å®¢æˆ·æ•°æ®")
        print("="*50)

        self.scraper = ChinaSocialScraper(platform, headless=False)
        self.scraper.run(keyword, limit)

        # è¯»å–æŠ“å–ç»“æœ
        excel_files = [f for f in os.listdir('.') if f.startswith(f'{platform}_leads_') and f.endswith('.xlsx')]
        if excel_files:
            latest_file = sorted(excel_files)[-1]
            df = pd.read_excel(latest_file)
            self.leads = df.to_dict('records')
            print(f"\nâœ… æˆåŠŸåŠ è½½ {len(self.leads)} æ¡çº¿ç´¢")
        else:
            print("\nâŒ æœªæ‰¾åˆ°æŠ“å–æ•°æ®")

    def step2_detect_signals(self):
        """æ­¥éª¤2: æ£€æµ‹æ„å›¾ä¿¡å·"""
        print("\n" + "="*50)
        print("ğŸ¯ æ­¥éª¤2: æ£€æµ‹æ„å›¾ä¿¡å·")
        print("="*50)

        if not self.leads:
            print("âŒ æ²¡æœ‰çº¿ç´¢æ•°æ®")
            return

        self.signals = []
        signal_stats = {}

        for lead in self.leads:
            content = lead.get('content', '')
            author = lead.get('username', 'æœªçŸ¥')
            platform = lead.get('platform', 'unknown')
            url = lead.get('url', '')

            # æ£€æµ‹ä¿¡å·
            signal = self.signal_detector.detect_from_content(content, author, platform, url)

            if signal:
                self.signals.append(signal)
                lead['signal'] = signal.to_dict()

                # ç»Ÿè®¡
                signal_type = signal.signal_name
                signal_stats[signal_type] = signal_stats.get(signal_type, 0) + 1
            else:
                lead['signal'] = None

        print(f"\nâœ… æ£€æµ‹åˆ° {len(self.signals)} ä¸ªæ„å›¾ä¿¡å·")

        if signal_stats:
            print("\nä¿¡å·åˆ†å¸ƒ:")
            for signal_type, count in sorted(signal_stats.items(), key=lambda x: x[1], reverse=True):
                print(f"  {signal_type}: {count}ä¸ª")

        # æŒ‰ç´§è¿«åº¦ç»Ÿè®¡
        urgency_stats = {}
        for signal in self.signals:
            urgency = signal.urgency.value
            urgency_stats[urgency] = urgency_stats.get(urgency, 0) + 1

        if urgency_stats:
            print("\nç´§è¿«åº¦åˆ†å¸ƒ:")
            for urgency in ['æé«˜', 'é«˜', 'ä¸­', 'ä½']:
                count = urgency_stats.get(urgency, 0)
                if count > 0:
                    print(f"  {urgency}: {count}ä¸ª ({count/len(self.signals)*100:.1f}%)")

    def step3_score_leads(self):
        """æ­¥éª¤3: AIè¯„åˆ†"""
        print("\n" + "="*50)
        print("ğŸ¯ æ­¥éª¤3: AIæ™ºèƒ½çº¿ç´¢è¯„åˆ†")
        print("="*50)

        if not self.leads:
            print("âŒ æ²¡æœ‰çº¿ç´¢æ•°æ®")
            return

        # æ‰¹é‡è¯„åˆ†
        scored_leads = self.scorer.batch_score(self.leads)
        self.leads = scored_leads

        # æ˜¾ç¤ºè¯„åˆ†ç»“æœ
        print(f"\nè¯„åˆ†å®Œæˆ:")
        grade_counts = {}
        for lead in self.leads:
            grade = lead.get('grade', 'D')
            grade_counts[grade] = grade_counts.get(grade, 0) + 1

        for grade in ['A', 'B', 'C', 'D']:
            count = grade_counts.get(grade, 0)
            print(f"  {grade}çº§: {count}ä¸ª ({count/len(self.leads)*100:.1f}%)")

        # ä¿å­˜è¯„åˆ†ç»“æœ
        df = pd.DataFrame(self.leads)
        filename = f"scored_leads_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        df.to_excel(filename, index=False)
        print(f"\nâœ… è¯„åˆ†ç»“æœå·²ä¿å­˜: {filename}")

    def step4_generate_signal_driven_emails(self, grade_filter: str = 'A'):
        """æ­¥éª¤4: ç”Ÿæˆä¿¡å·é©±åŠ¨é‚®ä»¶"""
        print("\n" + "="*50)
        print("âœ‰ï¸ æ­¥éª¤4: ç”Ÿæˆä¿¡å·é©±åŠ¨é‚®ä»¶")
        print("="*50)

        if not self.leads:
            print("âŒ æ²¡æœ‰çº¿ç´¢æ•°æ®")
            return []

        # ç­›é€‰æœ‰ä¿¡å·çš„é«˜ä»·å€¼çº¿ç´¢
        high_value_leads = [
            lead for lead in self.leads
            if lead.get('grade') == grade_filter and lead.get('signal') is not None
        ]

        print(f"\næ‰¾åˆ° {len(high_value_leads)} ä¸ª{grade_filter}çº§ä¸”æœ‰ä¿¡å·çš„çº¿ç´¢")

        if not high_value_leads:
            print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„çº¿ç´¢,å°è¯•é™ä½ç­›é€‰æ ‡å‡†...")
            return []

        # ä¸ºæ¯ä¸ªçº¿ç´¢ç”Ÿæˆé‚®ä»¶
        emails = []

        for idx, lead in enumerate(high_value_leads[:10]):  # åªå¤„ç†å‰10ä¸ª
            print(f"\n{'='*50}")
            print(f"è¿›åº¦: {idx+1}/{min(len(high_value_leads), 10)}")
            print(f"{'='*50}")
            print(f"çº¿ç´¢: {lead.get('username', 'æœªçŸ¥')}")
            print(f"è¯„åˆ†: {lead.get('score', 0)}")

            # é‡å»ºä¿¡å·å¯¹è±¡
            signal_dict = lead['signal']
            signal = IntentSignal(
                signal_type=SignalType.BEHAVIOR,
                signal_name=signal_dict['signal_name'],
                company=signal_dict['company'],
                contact_person=signal_dict['contact_person'],
                detected_at=datetime.fromisoformat(signal_dict['detected_at']),
                urgency=UrgencyLevel[signal_dict['urgency'].replace('æé«˜', 'CRITICAL').replace('é«˜', 'HIGH').replace('ä¸­', 'MEDIUM').replace('ä½', 'LOW')],
                confidence=signal_dict['confidence'],
                raw_data=signal_dict['raw_data'],
                pain_point=signal_dict['pain_point'],
                financial_loss=signal_dict['financial_loss']
            )

            print(f"ä¿¡å·: {signal.signal_name}")
            print(f"ç´§è¿«åº¦: {signal.urgency.value}")
            print(f"ç—›ç‚¹: {signal.pain_point}")

            # ç”Ÿæˆé‚®ä»¶
            print("\nğŸ¤– è°ƒç”¨DeepSeek APIç”Ÿæˆé‚®ä»¶...")
            email = self.email_generator.generate_signal_driven_email(signal, lead)

            print(f"\nğŸ“§ ä¸»é¢˜: {email['subject']}")
            print(f"ç”Ÿæˆæ–¹å¼: {email['generated_by']}")

            # ä¿å­˜åˆ°åˆ—è¡¨
            emails.append({
                'lead_name': lead.get('username', 'æœªçŸ¥'),
                'lead_score': lead.get('score', 0),
                'lead_grade': lead.get('grade', 'D'),
                'signal_type': signal.signal_name,
                'signal_urgency': signal.urgency.value,
                'pain_point': signal.pain_point,
                'subject': email['subject'],
                'body': email['body'],
                'generated_by': email['generated_by'],
                'generated_at': email['generated_at']
            })

            time.sleep(1)  # é¿å…APIé™æµ

        # ä¿å­˜é‚®ä»¶
        df = pd.DataFrame(emails)
        filename = f"signal_driven_emails_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
        df.to_excel(filename, index=False)
        print(f"\nâœ… é‚®ä»¶å·²ä¿å­˜: {filename}")

        return emails

    def step5_track_and_eliminate(self, emails: List[Dict]):
        """æ­¥éª¤5: è¿½è¸ªä¸é‡åŒ–æ·˜æ±°"""
        print("\n" + "="*50)
        print("ğŸ“Š æ­¥éª¤5: è¿½è¸ªä¸é‡åŒ–æ·˜æ±°")
        print("="*50)

        if not emails:
            print("âŒ æ²¡æœ‰é‚®ä»¶æ•°æ®")
            return

        print(f"\nå¼€å§‹è¿½è¸ª {len(emails)} å°é‚®ä»¶çš„å‘é€æ•ˆæœ...")
        print("\nâš ï¸ æ³¨æ„: è¿™æ˜¯æ¨¡æ‹Ÿè¿½è¸ª,å®é™…ä½¿ç”¨æ—¶éœ€è¦æ¥å…¥çœŸå®çš„é‚®ä»¶è¿½è¸ªç³»ç»Ÿ")

        # ä¸ºæ¯å°é‚®ä»¶åˆ›å»ºç­–ç•¥æŒ‡æ ‡
        for email in emails:
            strategy_id = f"strategy_{email['lead_name']}"
            if strategy_id not in self.strategy_metrics:
                self.strategy_metrics[strategy_id] = StrategyMetrics(strategy_id)

            # æ¨¡æ‹Ÿå‘é€
            metrics = self.strategy_metrics[strategy_id]
            metrics.total_sent += 1

            # æ¨¡æ‹Ÿé€è¾¾ç‡ 90%
            if random.random() < 0.9:
                metrics.delivered += 1

                # æ¨¡æ‹Ÿæ‰“å¼€ç‡ 25%
                if random.random() < 0.25:
                    metrics.opened += 1

                    # æ¨¡æ‹Ÿå›å¤ç‡ 5%
                    if random.random() < 0.05:
                        metrics.replied += 1

        # æ˜¾ç¤ºè¿½è¸ªç»“æœ
        print("\nğŸ“ˆ è¿½è¸ªç»“æœ:")
        total_sent = sum(m.total_sent for m in self.strategy_metrics.values())
        total_delivered = sum(m.delivered for m in self.strategy_metrics.values())
        total_opened = sum(m.opened for m in self.strategy_metrics.values())
        total_replied = sum(m.replied for m in self.strategy_metrics.values())

        print(f"  æ€»å‘é€: {total_sent}")
        print(f"  é€è¾¾: {total_delivered} ({total_delivered/total_sent*100:.1f}%)")
        print(f"  æ‰“å¼€: {total_opened} ({total_opened/total_delivered*100:.1f}%)")
        print(f"  å›å¤: {total_replied} ({total_replied/total_delivered*100:.1f}%)")

        # é‡åŒ–æ·˜æ±°æ£€æŸ¥
        print("\nğŸ” é‡åŒ–æ·˜æ±°æ£€æŸ¥ (æ­¢æŸçº¿: 200æ¬¡è§¦è¾¾, å›å¤ç‡<2%):")
        for strategy_id, metrics in self.strategy_metrics.items():
            should_eliminate, reason = metrics.should_eliminate(
                stop_loss_threshold=0.02,
                min_sample_size=200
            )

            if should_eliminate:
                print(f"  âŒ {strategy_id}: {reason}")
            else:
                print(f"  âœ… {strategy_id}: {reason}")

    def run_complete_workflow(self):
        """è¿è¡Œå®Œæ•´å·¥ä½œæµ"""
        print("\n" + "="*50)
        print("ğŸš€ ä¿¡å·é©±åŠ¨è·å®¢ç³»ç»Ÿ - ç•™å­¦è¡Œä¸šä¸“ç”¨")
        print("="*50)

        print("\nè¿™ä¸ªç³»ç»Ÿå°†å¸®æ‚¨:")
        print("1. ä»ç¤¾äº¤åª’ä½“æŠ“å–çœŸå®æ½œåœ¨å®¢æˆ·")
        print("2. æ£€æµ‹æ„å›¾ä¿¡å·(è¡Œä¸º/æŠ€æœ¯/äººå‘˜)")
        print("3. AIæ™ºèƒ½è¯„åˆ†,è¯†åˆ«é«˜ä»·å€¼çº¿ç´¢")
        print("4. ç”Ÿæˆä¿¡å·é©±åŠ¨çš„ä¸ªæ€§åŒ–é‚®ä»¶(DeepSeek API)")
        print("5. è¿½è¸ªæ•ˆæœå¹¶æ‰§è¡Œé‡åŒ–æ·˜æ±°(200æ¬¡æ­¢æŸçº¿)")

        # è¾“å…¥å‚æ•°
        print("\n" + "="*50)
        platform = input("\nè¯·é€‰æ‹©å¹³å° (xiaohongshu/zhihu/weibo): ").strip().lower()
        if platform not in ['xiaohongshu', 'zhihu', 'weibo']:
            print("âŒ æš‚ä¸æ”¯æŒè¯¥å¹³å°")
            return

        keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ä¾‹å¦‚: ç¾å›½ç•™å­¦): ").strip()
        if not keyword:
            keyword = "ç¾å›½ç•™å­¦"

        limit = input("è¯·è¾“å…¥è¦æŠ“å–çš„å†…å®¹æ•°é‡ (é»˜è®¤10): ").strip()
        limit = int(limit) if limit else 10

        # æ‰§è¡Œå®Œæ•´æµç¨‹
        try:
            # æ­¥éª¤1: æŠ“å–
            self.step1_scrape_leads(platform, keyword, limit)

            if not self.leads:
                print("\nâŒ æŠ“å–å¤±è´¥,é€€å‡º")
                return

            # æ­¥éª¤2: æ£€æµ‹ä¿¡å·
            self.step2_detect_signals()

            # æ­¥éª¤3: è¯„åˆ†
            self.step3_score_leads()

            # æ­¥éª¤4: ç”Ÿæˆä¿¡å·é©±åŠ¨é‚®ä»¶
            emails = self.step4_generate_signal_driven_emails(grade_filter='A')

            if not emails:
                print("\nâš ï¸ æ²¡æœ‰Açº§çº¿ç´¢,å°è¯•Bçº§...")
                emails = self.step4_generate_signal_driven_emails(grade_filter='B')

            if not emails:
                print("\nâŒ æ²¡æœ‰é«˜ä»·å€¼çº¿ç´¢")
                return

            # æ­¥éª¤5: è¿½è¸ªä¸æ·˜æ±°
            self.step5_track_and_eliminate(emails)

            # å®Œæˆ
            print("\n" + "="*50)
            print("ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•!")
            print("="*50)

            print("\nç”Ÿæˆçš„æ–‡ä»¶:")
            print(f"1. scored_leads_*.xlsx - è¯„åˆ†åçš„çº¿ç´¢(å«ä¿¡å·)")
            print(f"2. signal_driven_emails_*.xlsx - ä¿¡å·é©±åŠ¨é‚®ä»¶")

            print("\nä¸‹ä¸€æ­¥:")
            print("1. æŸ¥çœ‹Excelæ–‡ä»¶")
            print("2. å¤åˆ¶é‚®ä»¶å†…å®¹")
            print("3. å‘é€é‚®ä»¶å¹¶è¿½è¸ªæ•ˆæœ")
            print("4. å½“è§¦è¾¾200æ¬¡ä¸”å›å¤ç‡<2%æ—¶,ç«‹å³åœæ­¢è¯¥ç­–ç•¥")

        except Exception as e:
            print(f"\nâŒ æ‰§è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    if not SELENIUM_AVAILABLE:
        print("\nâŒ ç¼ºå°‘ä¾èµ–,æ— æ³•è¿è¡Œ")
        print("è¯·å®‰è£…: pip install selenium undetected-chromedriver pandas openpyxl")
        return

    system = CompleteLeadGenerationSystem()
    system.run_complete_workflow()


if __name__ == "__main__":
    main()
