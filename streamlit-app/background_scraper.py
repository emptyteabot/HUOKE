"""
åå°æŠ“å–ä»»åŠ¡ç³»ç»Ÿ

ä½¿ç”¨çº¿ç¨‹æ± åœ¨åå°è¿è¡ŒæŠ“å–ä»»åŠ¡,ä¸é˜»å¡Webç•Œé¢
é€‚åˆéƒ¨ç½²åˆ°äº‘ç«¯æœåŠ¡å™¨
"""

import threading
import queue
import time
import json
from datetime import datetime
from typing import Dict, List, Optional
import uuid


class ScrapingTask:
    """æŠ“å–ä»»åŠ¡"""

    def __init__(self, task_id: str, keywords: str, platforms: List[str], user_id: str):
        self.task_id = task_id
        self.keywords = keywords
        self.platforms = platforms
        self.user_id = user_id
        self.status = 'pending'  # pending, running, completed, failed
        self.progress = 0
        self.results = {}
        self.error = None
        self.created_at = datetime.now().isoformat()
        self.started_at = None
        self.completed_at = None

    def to_dict(self):
        return {
            'task_id': self.task_id,
            'keywords': self.keywords,
            'platforms': self.platforms,
            'user_id': self.user_id,
            'status': self.status,
            'progress': self.progress,
            'results': self.results,
            'error': self.error,
            'created_at': self.created_at,
            'started_at': self.started_at,
            'completed_at': self.completed_at
        }


class BackgroundScraper:
    """åå°æŠ“å–å™¨"""

    def __init__(self, max_workers: int = 2):
        self.task_queue = queue.Queue()
        self.tasks = {}  # task_id -> ScrapingTask
        self.max_workers = max_workers
        self.workers = []
        self.running = False

    def start(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹"""
        if self.running:
            return

        self.running = True

        for i in range(self.max_workers):
            worker = threading.Thread(target=self._worker, daemon=True)
            worker.start()
            self.workers.append(worker)

        print(f"âœ… åå°æŠ“å–å™¨å·²å¯åŠ¨ ({self.max_workers} ä¸ªå·¥ä½œçº¿ç¨‹)")

    def stop(self):
        """åœæ­¢å·¥ä½œçº¿ç¨‹"""
        self.running = False
        print("â¹ï¸ åå°æŠ“å–å™¨å·²åœæ­¢")

    def submit_task(self, keywords: str, platforms: List[str], user_id: str) -> str:
        """
        æäº¤æŠ“å–ä»»åŠ¡

        Args:
            keywords: æœç´¢å…³é”®è¯
            platforms: å¹³å°åˆ—è¡¨
            user_id: ç”¨æˆ·ID

        Returns:
            str: ä»»åŠ¡ID
        """
        task_id = str(uuid.uuid4())
        task = ScrapingTask(task_id, keywords, platforms, user_id)

        self.tasks[task_id] = task
        self.task_queue.put(task)

        print(f"ğŸ“ ä»»åŠ¡å·²æäº¤: {task_id} - {keywords}")

        return task_id

    def get_task(self, task_id: str) -> Optional[Dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        task = self.tasks.get(task_id)
        return task.to_dict() if task else None

    def get_user_tasks(self, user_id: str) -> List[Dict]:
        """è·å–ç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡"""
        return [
            task.to_dict()
            for task in self.tasks.values()
            if task.user_id == user_id
        ]

    def _worker(self):
        """å·¥ä½œçº¿ç¨‹"""
        while self.running:
            try:
                # è·å–ä»»åŠ¡ (è¶…æ—¶1ç§’,é¿å…é˜»å¡)
                task = self.task_queue.get(timeout=1)

                # æ‰§è¡Œä»»åŠ¡
                self._execute_task(task)

                self.task_queue.task_done()

            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")

    def _execute_task(self, task: ScrapingTask):
        """æ‰§è¡ŒæŠ“å–ä»»åŠ¡"""
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.task_id}")

        task.status = 'running'
        task.started_at = datetime.now().isoformat()

        try:
            # æ–¹æ¡ˆ1: ä½¿ç”¨çœŸå®SeleniumæŠ“å– (å¦‚æœåœ¨æœ¬åœ°æˆ–æœ‰Chromeçš„æœåŠ¡å™¨)
            try:
                from real_scraper import MultiPlatformScraper

                scraper = MultiPlatformScraper(headless=True)
                results = scraper.scrape_all(task.keywords, task.platforms, limit=10)

                task.results = results
                task.status = 'completed'
                task.progress = 100

            except ImportError:
                # æ–¹æ¡ˆ2: å¦‚æœæ²¡æœ‰Selenium,ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
                print("âš ï¸ Seleniumä¸å¯ç”¨,ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                from platform_scraper import MultiPlatformAggregator

                aggregator = MultiPlatformAggregator()
                results = aggregator.search_all_platforms(task.keywords, task.platforms)

                task.results = results
                task.status = 'completed'
                task.progress = 100

            task.completed_at = datetime.now().isoformat()

            print(f"âœ… ä»»åŠ¡å®Œæˆ: {task.task_id}")

        except Exception as e:
            task.status = 'failed'
            task.error = str(e)
            task.completed_at = datetime.now().isoformat()

            print(f"âŒ ä»»åŠ¡å¤±è´¥: {task.task_id} - {e}")


# å…¨å±€å•ä¾‹
_scraper_instance = None


def get_background_scraper() -> BackgroundScraper:
    """è·å–åå°æŠ“å–å™¨å•ä¾‹"""
    global _scraper_instance

    if _scraper_instance is None:
        _scraper_instance = BackgroundScraper(max_workers=2)
        _scraper_instance.start()

    return _scraper_instance


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å¯åŠ¨åå°æŠ“å–å™¨
    scraper = get_background_scraper()

    # æäº¤ä»»åŠ¡
    task_id = scraper.submit_task(
        keywords="ç¾å›½ç•™å­¦",
        platforms=["xiaohongshu", "zhihu"],
        user_id="test_user"
    )

    print(f"ä»»åŠ¡ID: {task_id}")

    # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
    while True:
        task = scraper.get_task(task_id)
        print(f"çŠ¶æ€: {task['status']} - è¿›åº¦: {task['progress']}%")

        if task['status'] in ['completed', 'failed']:
            break

        time.sleep(2)

    # æŸ¥çœ‹ç»“æœ
    if task['status'] == 'completed':
        print(f"âœ… æŠ“å–å®Œæˆ!")
        print(json.dumps(task['results'], indent=2, ensure_ascii=False))
    else:
        print(f"âŒ æŠ“å–å¤±è´¥: {task['error']}")
