# 用Gemini完成LeadPulse产品的完整工作流

## 🎯 核心策略

**把Gemini当成你的全职技术合伙人:**
- 数据收集 → Gemini Deep Research
- 代码重构 → Gemini + GitHub Context
- 测试调试 → Gemini分析错误日志
- 文档编写 → Gemini生成
- 产品迭代 → Gemini提供方案

---

## 📋 工作流程

### 阶段1: 让Gemini理解项目 (已完成✅)

**你已经做的:**
- ✅ 清理项目,只保留核心文件
- ✅ 提交到GitHub: https://github.com/emptyteabot/HUOKE
- ✅ 创建 GEMINI_CONTEXT.md 说明文档

**下一步:**
```
发给Gemini:

"我有一个留学获客系统项目,需要你作为我的技术合伙人。

项目GitHub: https://github.com/emptyteabot/HUOKE

请先完成以下任务:

1. 克隆并分析整个项目
   - 阅读 README.md 了解项目概况
   - 阅读 GEMINI_CONTEXT.md 了解当前状态和问题
   - 分析所有核心代码文件

2. 生成项目分析报告
   - 项目架构图
   - 核心功能模块
   - 技术栈
   - 当前问题清单
   - 优先级排序

3. 提出改进建议
   - 代码质量问题
   - 架构优化方向
   - 功能缺失
   - 性能瓶颈

请以Markdown格式输出完整报告。"
```

---

### 阶段2: 数据收集 (最优先)

#### 任务2.1: 用Gemini收集真实客户数据

**Prompt:**
```
基于项目中的 `Gemini获客Prompt工程.md`,执行以下任务:

**任务: 收集150-200个真实的留学潜在客户**

执行步骤:
1. 使用 Prompt 1 找到客户聚集平台
2. 使用 Prompt 2-6 从各平台收集数据:
   - 小红书 (50个)
   - 知乎 (30个)
   - 豆瓣 (20个)
   - 微博 (25个)
   - 论坛 (40个)

3. 对每个客户提取:
   - 基本信息(姓名/昵称)
   - 联系方式(邮箱/微信/手机号)
   - 背景(学校/专业/GPA)
   - 目标(国家/学校/专业)
   - 预算范围
   - 痛点和需求
   - 意向评分(1-10)
   - 优先级(S/A/B)

4. 以JSON格式输出,格式参考 GEMINI_CONTEXT.md

重点:
- 必须是真实用户(不是AI生成)
- 尽可能提取联系方式
- 评估意向等级
- 标注数据来源和时间

开始执行!
```

**预期输出:**
- `gemini_leads.json` - 150-200个真实客户数据
- 数据质量报告(联系方式完整率、意向分布等)

#### 任务2.2: 数据验证和清洗

**Prompt:**
```
我收到了你提供的客户数据 gemini_leads.json。

请帮我:
1. 验证数据质量
   - 检查必填字段完整性
   - 验证邮箱/手机号格式
   - 检测重复数据

2. 数据清洗
   - 去重(同一个人在多个平台)
   - 标准化格式(统一字段名)
   - 补充缺失信息(从其他字段推断)

3. 数据增强
   - 根据行为推断意向等级
   - 生成个性化触达话术
   - 推荐最佳联系时间

4. 生成清洗报告
   - 原始数据: X条
   - 去重后: Y条
   - 有效联系方式: Z条
   - S/A/B级分布

输出:
- gemini_leads_cleaned.json (清洗后的数据)
- data_quality_report.md (质量报告)
```

---

### 阶段3: 代码重构 (提升质量)

#### 任务3.1: 重构爬虫代码

**Prompt:**
```
项目中有两个爬虫文件存在严重问题:
- scrapers/xiaohongshu_scraper_v2.py
- scrapers/zhihu_scraper_v2.py

问题:
1. 大量使用 time.sleep() 硬等待
2. 用 except Exception: continue 掩盖错误
3. 代码高度冗余
4. 没有重试机制
5. 选择器写死,容易失效

我已经创建了:
- scrapers/base_scraper.py (基类)
- scrapers/xiaohongshu_scraper_pro.py (重构示例)

请帮我:
1. 基于 base_scraper.py 重构 zhihu_scraper_v2.py
   - 继承 BaseSocialScraper
   - 使用显式等待替代 time.sleep()
   - 添加重试机制
   - 多选择器策略
   - 结构化日志

2. 优化 xiaohongshu_scraper_pro.py
   - 检查是否有遗漏的错误处理
   - 优化选择器策略
   - 添加更多容错机制

3. 创建统一的爬虫管理器
   - scraper_manager_pro.py
   - 统一调度小红书/知乎爬虫
   - 并发控制
   - 错误恢复
   - 进度追踪

输出完整代码,并说明改进点。
```

#### 任务3.2: 优化邮件系统

**Prompt:**
```
项目中的邮件系统 email_auto_sender.py 需要优化。

当前问题:
1. DeepSeek API调用没有错误处理
2. SendGrid发送失败没有重试
3. 没有发送速率限制(容易被封)
4. A/B测试逻辑不完整
5. 效果追踪数据不准确

请帮我:
1. 添加完善的错误处理
   - API调用重试(指数退避)
   - 发送失败降级(使用模板)
   - 网络超时处理

2. 实现速率限制
   - SendGrid免费版: 100封/天
   - 自动分批发送
   - 避免触发反垃圾机制

3. 完善A/B测试
   - 自动分配测试组
   - 追踪打开/点击/回复
   - 生成对比报告
   - 自动选择最优版本

4. 优化效果追踪
   - 实时追踪发送状态
   - 记录打开时间/地点
   - 分析回复内容
   - 计算ROI

输出优化后的代码。
```

#### 任务3.3: 完善信号检测系统

**Prompt:**
```
项目中的信号检测系统需要优化:
- intent_signal_hijacker.py
- signal_driven_outbound.py

当前问题:
1. 信号规则写死,不够灵活
2. 没有机器学习,无法自动优化
3. 信号权重不合理
4. 缺少实时监控

请帮我:
1. 重构信号检测引擎
   - 配置化信号规则(YAML/JSON)
   - 动态调整信号权重
   - 支持自定义信号类型

2. 添加机器学习
   - 基于历史数据训练模型
   - 预测客户转化概率
   - 自动优化信号权重

3. 实现实时监控
   - 监控新发布的内容
   - 实时检测买入信号
   - 立即触发触达(黄金窗口期)

4. 生成信号分析报告
   - 哪些信号转化率最高
   - 最佳触达时机
   - 优化建议

输出优化后的代码和配置文件。
```

---

### 阶段4: 测试和调试

#### 任务4.1: 编写测试用例

**Prompt:**
```
项目缺少完整的测试。

请帮我创建:
1. 单元测试
   - tests/test_scraper.py (爬虫测试)
   - tests/test_email.py (邮件测试)
   - tests/test_signal.py (信号测试)

2. 集成测试
   - tests/test_integration.py (端到端测试)

3. 性能测试
   - tests/test_performance.py (压力测试)

4. Mock数据
   - tests/fixtures/ (测试数据)

要求:
- 使用 pytest 框架
- 覆盖率 >80%
- 包含边界情况测试
- 包含错误处理测试

输出完整的测试代码。
```

#### 任务4.2: 调试和修复

**Prompt:**
```
我运行测试时遇到以下错误:

[粘贴错误日志]

请帮我:
1. 分析错误原因
2. 定位问题代码
3. 提供修复方案
4. 解释为什么会出现这个错误
5. 如何避免类似问题

输出修复后的代码。
```

---

### 阶段5: 功能迭代

#### 任务5.1: 添加新平台支持

**Prompt:**
```
我想添加更多平台支持:
- 微博
- 豆瓣
- 留学论坛(寄托天下、一亩三分地)

请帮我:
1. 分析这些平台的特点
   - 数据结构
   - 反爬机制
   - 登录方式

2. 基于 base_scraper.py 创建爬虫
   - weibo_scraper_pro.py
   - douban_scraper_pro.py
   - forum_scraper_pro.py

3. 集成到 scraper_manager_pro.py

4. 更新文档

输出完整代码。
```

#### 任务5.2: 添加自动化工作流

**Prompt:**
```
我想实现完全自动化的获客流程:

Day 1:
- 自动抓取新客户(每天早上9点)
- 自动评分和分类
- 发送首次邮件

Day 3:
- 自动发送跟进邮件
- 追踪打开率

Day 7:
- 发送第三封邮件
- 分析回复内容

Day 14:
- 最后一封邮件
- 生成效果报告

请帮我:
1. 设计自动化架构
2. 实现定时任务(使用 APScheduler)
3. 添加错误恢复机制
4. 实现进度通知(邮件/微信)

输出完整代码。
```

---

### 阶段6: 部署和运维

#### 任务6.1: Docker化部署

**Prompt:**
```
我想把系统部署到服务器。

请帮我:
1. 创建 Dockerfile
2. 创建 docker-compose.yml
3. 配置环境变量
4. 编写部署文档

要求:
- 支持一键部署
- 包含数据库(PostgreSQL)
- 包含Redis缓存
- 包含Nginx反向代理

输出完整配置文件和文档。
```

#### 任务6.2: 监控和告警

**Prompt:**
```
我需要监控系统运行状态。

请帮我:
1. 添加健康检查
   - 爬虫是否正常
   - 邮件是否发送成功
   - API是否可用

2. 实现日志聚合
   - 使用 ELK Stack
   - 或使用 Loki

3. 添加告警机制
   - 爬虫失败 → 发邮件
   - 邮件发送失败 → 发微信
   - 系统崩溃 → 发短信

4. 创建监控Dashboard
   - Grafana可视化
   - 实时数据展示

输出配置文件和代码。
```

---

### 阶段7: 文档和营销

#### 任务7.1: 完善文档

**Prompt:**
```
项目需要完整的文档。

请帮我创建:
1. 用户手册
   - 快速开始
   - 功能说明
   - 常见问题
   - 故障排查

2. 开发文档
   - 架构设计
   - API文档
   - 代码规范
   - 贡献指南

3. 部署文档
   - 环境要求
   - 安装步骤
   - 配置说明
   - 升级指南

4. 视频教程脚本
   - 5分钟快速上手
   - 15分钟完整教程
   - 30分钟高级功能

输出完整文档(Markdown格式)。
```

#### 任务7.2: 营销材料

**Prompt:**
```
我需要营销材料来推广产品。

请帮我创建:
1. Landing Page文案
   - 标题(吸引眼球)
   - 痛点描述
   - 解决方案
   - 功能特性
   - 客户案例
   - 定价方案
   - CTA按钮

2. 销售演示PPT
   - 10页精简版
   - 包含数据和案例

3. 冷邮件模板
   - 5个不同版本
   - A/B测试用

4. 社交媒体文案
   - 小红书笔记(3篇)
   - 知乎回答(2篇)
   - 微信公众号文章(1篇)

输出完整文案。
```

---

## 🔄 持续迭代流程

### 每日工作流

**早上(9:00-10:00):**
```
发给Gemini:

"早上好!今天的任务:

1. 检查昨天的数据收集结果
   - 新增客户数量
   - 数据质量如何
   - 有没有错误

2. 分析昨天的邮件效果
   - 发送了多少封
   - 打开率/回复率
   - 哪些文案效果好

3. 提出今天的优化建议
   - 需要调整什么
   - 优先级排序

4. 生成今日任务清单

开始!"
```

**下午(14:00-15:00):**
```
发给Gemini:

"下午好!我遇到了以下问题:

[描述问题]

请帮我:
1. 分析问题原因
2. 提供解决方案
3. 给出代码示例
4. 解释原理

谢谢!"
```

**晚上(20:00-21:00):**
```
发给Gemini:

"今天的工作总结:

完成的任务:
- [任务1]
- [任务2]

遇到的问题:
- [问题1]
- [问题2]

请帮我:
1. 评估今天的进度
2. 分析遇到的问题
3. 制定明天的计划
4. 给出改进建议

晚安!"
```

---

## 💡 高级技巧

### 技巧1: 让Gemini主动思考

**不要问:**
> "这段代码有问题吗?"

**要问:**
> "分析这段代码,从以下角度:
> 1. 性能瓶颈
> 2. 安全隐患
> 3. 可维护性
> 4. 扩展性
> 5. 最佳实践
>
> 给出具体的改进建议和代码示例。"

### 技巧2: 提供完整上下文

**不要问:**
> "为什么报错?"

**要问:**
> "我在执行X任务时遇到错误:
>
> 环境:
> - Python 3.9
> - Windows 11
> - 依赖版本: [列出]
>
> 错误日志:
> [完整日志]
>
> 相关代码:
> [粘贴代码]
>
> 我尝试过:
> - [尝试1]
> - [尝试2]
>
> 请帮我分析原因并提供解决方案。"

### 技巧3: 要求结构化输出

**不要问:**
> "帮我优化这段代码"

**要问:**
> "优化这段代码,并以以下格式输出:
>
> ## 问题分析
> - 问题1: [描述]
> - 问题2: [描述]
>
> ## 优化方案
> - 方案1: [描述] (优先级: 高)
> - 方案2: [描述] (优先级: 中)
>
> ## 优化后代码
> ```python
> [完整代码]
> ```
>
> ## 性能对比
> | 指标 | 优化前 | 优化后 | 提升 |
> |------|--------|--------|------|
>
> ## 注意事项
> - [注意1]
> - [注意2]"

### 技巧4: 分阶段执行

**不要问:**
> "帮我完成整个项目"

**要问:**
> "我们分3个阶段完成:
>
> 阶段1: 数据收集(本周)
> - 任务1.1: 收集小红书数据
> - 任务1.2: 收集知乎数据
> - 任务1.3: 数据清洗
>
> 现在先完成任务1.1,其他的后面再做。
>
> 开始执行任务1.1!"

---

## 📊 效果追踪

### 每周回顾

**发给Gemini:**
```
本周工作回顾:

数据:
- 收集客户: X个
- 发送邮件: Y封
- 打开率: Z%
- 回复率: W%
- 成交: N人

代码:
- 提交次数: X次
- 新增功能: Y个
- 修复Bug: Z个

问题:
- [问题1]
- [问题2]

请帮我:
1. 分析本周数据
2. 找出问题原因
3. 提出改进建议
4. 制定下周计划

生成周报(Markdown格式)。
```

---

## 🎯 最终目标

**30天后,你将拥有:**
- ✅ 150-200个真实客户数据
- ✅ 生产级的爬虫系统
- ✅ 自动化的邮件营销系统
- ✅ 完善的监控和告警
- ✅ 完整的文档和测试
- ✅ 第一批付费客户

**Gemini帮你完成:**
- 90%的代码编写
- 100%的数据收集
- 100%的文档编写
- 80%的测试用例
- 100%的问题分析

**你只需要:**
- 提出需求
- 审核代码
- 测试功能
- 做决策

---

## 🚀 立即开始

**第一步: 发给Gemini**
```
我有一个留学获客系统项目,需要你作为我的技术合伙人。

项目GitHub: https://github.com/emptyteabot/HUOKE

请先阅读以下文件:
1. README.md
2. GEMINI_CONTEXT.md
3. Gemini获客Prompt工程.md

然后生成:
1. 项目分析报告
2. 30天开发计划
3. 优先级任务清单

开始!
```

**从现在开始,所有工作都交给Gemini!**
