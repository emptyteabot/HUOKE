"""
ä¸­å›½ç¤¾äº¤åª’ä½“è‡ªåŠ¨è·å®¢å·¥å…· - å…¨å¹³å°æ”¯æŒ

æ”¯æŒå¹³å°:
1. å°çº¢ä¹¦ - çˆ¬å–ç¬”è®°è¯„è®º
2. çŸ¥ä¹ - çˆ¬å–é—®é¢˜å›ç­”å’Œè¯„è®º
3. æŠ–éŸ³ - çˆ¬å–è§†é¢‘è¯„è®º
4. å¾®åš - çˆ¬å–å¾®åšè¯„è®º
5. Bç«™ - çˆ¬å–è§†é¢‘è¯„è®º
6. è±†ç“£ - çˆ¬å–å°ç»„å¸–å­

ä½¿ç”¨æ–¹æ³•:
python china_social_scraper.py
"""

import time
import random
import json
import pandas as pd
from datetime import datetime
from typing import List, Dict
import os
import sys

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver.common.keys import Keys
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_AVAILABLE = True
except ImportError:
    SELENIUM_AVAILABLE = False
    print("âŒ è¯·å…ˆå®‰è£…ä¾èµ–: pip install selenium undetected-chromedriver pandas openpyxl")
    sys.exit(1)


class ChinaSocialScraper:
    """ä¸­å›½ç¤¾äº¤åª’ä½“è‡ªåŠ¨è·å®¢å·¥å…·"""

    def __init__(self, platform: str, headless: bool = False):
        self.platform = platform
        self.headless = headless
        self.driver = None
        self.logged_in = False
        self.results = []

        # å¹³å°é…ç½®
        self.platform_config = {
            'xiaohongshu': {
                'name': 'å°çº¢ä¹¦',
                'url': 'https://www.xiaohongshu.com',
                'search_url': 'https://www.xiaohongshu.com/search_result?keyword={keyword}',
                'login_check': '.avatar, .user-avatar'
            },
            'zhihu': {
                'name': 'çŸ¥ä¹',
                'url': 'https://www.zhihu.com',
                'search_url': 'https://www.zhihu.com/search?type=content&q={keyword}',
                'login_check': '.Avatar'
            },
            'douyin': {
                'name': 'æŠ–éŸ³',
                'url': 'https://www.douyin.com',
                'search_url': 'https://www.douyin.com/search/{keyword}',
                'login_check': '.avatar'
            },
            'weibo': {
                'name': 'å¾®åš',
                'url': 'https://weibo.com',
                'search_url': 'https://s.weibo.com/weibo?q={keyword}',
                'login_check': '.Avatar_face'
            },
            'bilibili': {
                'name': 'Bç«™',
                'url': 'https://www.bilibili.com',
                'search_url': 'https://search.bilibili.com/all?keyword={keyword}',
                'login_check': '.header-avatar-wrap'
            },
            'douban': {
                'name': 'è±†ç“£',
                'url': 'https://www.douban.com',
                'search_url': 'https://www.douban.com/search?q={keyword}',
                'login_check': '.nav-user-account'
            }
        }

    def init_driver(self):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        print(f"ğŸš€ å¯åŠ¨æµè§ˆå™¨ ({self.platform_config[self.platform]['name']})...")

        options = uc.ChromeOptions()
        if self.headless:
            options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')

        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        ]
        options.add_argument(f'user-agent={random.choice(user_agents)}')

        self.driver = uc.Chrome(options=options)
        self.driver.set_page_load_timeout(30)
        self.driver.maximize_window()

        print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")

    def login(self):
        """ç™»å½•å¹³å°"""
        config = self.platform_config[self.platform]

        print(f"\n{'='*50}")
        print(f"ğŸ” ç™»å½•{config['name']}")
        print("="*50)

        self.driver.get(config['url'])
        time.sleep(3)

        print(f"\nè¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•{config['name']}:")
        print("1. æ‰«ç ç™»å½• æˆ– æ‰‹æœºå·ç™»å½•")
        print("2. ç™»å½•æˆåŠŸå,åœ¨è¿™é‡Œè¾“å…¥ 'ok' å¹¶æŒ‰å›è½¦...")

        while True:
            user_input = input("\nè¾“å…¥ 'ok' ç»§ç»­: ").strip().lower()
            if user_input == 'ok':
                break

        # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
        try:
            self.driver.find_element(By.CSS_SELECTOR, config['login_check'])
            print(f"âœ… {config['name']}ç™»å½•æˆåŠŸ!")
            self.logged_in = True
            return True
        except:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°ç™»å½•,ç»§ç»­å°è¯•...")
            self.logged_in = True
            return True

    def random_sleep(self, min_sec: float = 2, max_sec: float = 5):
        """éšæœºå»¶è¿Ÿ"""
        time.sleep(random.uniform(min_sec, max_sec))

    def search_keyword(self, keyword: str):
        """æœç´¢å…³é”®è¯"""
        config = self.platform_config[self.platform]
        print(f"\nğŸ” åœ¨{config['name']}æœç´¢: {keyword}")

        try:
            search_url = config['search_url'].format(keyword=keyword)
            self.driver.get(search_url)
            self.random_sleep(3, 5)

            print("âœ… æœç´¢é¡µé¢åŠ è½½æˆåŠŸ")
            return True

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return False

    def scrape_xiaohongshu(self, keyword: str, limit: int = 10) -> List[Dict]:
        """çˆ¬å–å°çº¢ä¹¦"""
        print(f"\nğŸ“± å¼€å§‹çˆ¬å–å°çº¢ä¹¦...")

        results = []

        try:
            # æ»šåŠ¨åŠ è½½
            for i in range(3):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.random_sleep(2, 3)

            # è·å–ç¬”è®°é“¾æ¥
            note_links = []
            note_elements = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/explore/']")

            for elem in note_elements[:limit]:
                try:
                    link = elem.get_attribute("href")
                    if link and link not in note_links:
                        note_links.append(link)
                except:
                    continue

            print(f"  æ‰¾åˆ° {len(note_links)} ä¸ªç¬”è®°")

            # çˆ¬å–æ¯ä¸ªç¬”è®°çš„è¯„è®º
            for idx, note_url in enumerate(note_links):
                print(f"  è¿›åº¦: {idx+1}/{len(note_links)}")

                self.driver.get(note_url)
                self.random_sleep(3, 5)

                # æ»šåŠ¨åˆ°è¯„è®ºåŒº
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.random_sleep(2, 3)

                # æŸ¥æ‰¾è¯„è®º
                comment_elements = self.driver.find_elements(By.CSS_SELECTOR, ".comment-item, [class*='comment']")

                for comment_elem in comment_elements[:20]:
                    try:
                        username = comment_elem.find_element(By.CSS_SELECTOR, ".username, [class*='username']").text.strip()
                        content = comment_elem.find_element(By.CSS_SELECTOR, ".content, [class*='content']").text.strip()

                        if username and content:
                            results.append({
                                'platform': 'å°çº¢ä¹¦',
                                'username': username,
                                'content': content,
                                'source_url': note_url,
                                'scraped_at': datetime.now().isoformat()
                            })

                    except:
                        continue

                self.random_sleep(3, 6)

        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥: {e}")

        return results

    def scrape_zhihu(self, keyword: str, limit: int = 10) -> List[Dict]:
        """çˆ¬å–çŸ¥ä¹"""
        print(f"\nğŸ“š å¼€å§‹çˆ¬å–çŸ¥ä¹...")

        results = []

        try:
            # æ»šåŠ¨åŠ è½½
            for i in range(3):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.random_sleep(2, 3)

            # è·å–é—®é¢˜/æ–‡ç« é“¾æ¥
            content_links = []
            link_elements = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/question/'], a[href*='/answer/']")

            for elem in link_elements[:limit]:
                try:
                    link = elem.get_attribute("href")
                    if link and link not in content_links:
                        content_links.append(link)
                except:
                    continue

            print(f"  æ‰¾åˆ° {len(content_links)} ä¸ªå†…å®¹")

            # çˆ¬å–æ¯ä¸ªå†…å®¹çš„è¯„è®º
            for idx, content_url in enumerate(content_links):
                print(f"  è¿›åº¦: {idx+1}/{len(content_links)}")

                self.driver.get(content_url)
                self.random_sleep(3, 5)

                # æ»šåŠ¨åˆ°è¯„è®ºåŒº
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.random_sleep(2, 3)

                # æŸ¥æ‰¾è¯„è®º
                comment_elements = self.driver.find_elements(By.CSS_SELECTOR, ".CommentItem, [class*='Comment']")

                for comment_elem in comment_elements[:20]:
                    try:
                        username = comment_elem.find_element(By.CSS_SELECTOR, ".UserLink, [class*='UserLink']").text.strip()
                        content = comment_elem.find_element(By.CSS_SELECTOR, ".CommentContent, [class*='Content']").text.strip()

                        if username and content:
                            results.append({
                                'platform': 'çŸ¥ä¹',
                                'username': username,
                                'content': content,
                                'source_url': content_url,
                                'scraped_at': datetime.now().isoformat()
                            })

                    except:
                        continue

                self.random_sleep(3, 6)

        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥: {e}")

        return results

    def scrape_weibo(self, keyword: str, limit: int = 10) -> List[Dict]:
        """çˆ¬å–å¾®åš"""
        print(f"\nğŸ¦ å¼€å§‹çˆ¬å–å¾®åš...")

        results = []

        try:
            # æ»šåŠ¨åŠ è½½
            for i in range(3):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                self.random_sleep(2, 3)

            # è·å–å¾®åšé“¾æ¥
            weibo_elements = self.driver.find_elements(By.CSS_SELECTOR, ".card-wrap, [class*='card']")[:limit]

            print(f"  æ‰¾åˆ° {len(weibo_elements)} æ¡å¾®åš")

            for idx, weibo_elem in enumerate(weibo_elements):
                print(f"  è¿›åº¦: {idx+1}/{len(weibo_elements)}")

                try:
                    # ç‚¹å‡»æŸ¥çœ‹è¯„è®º
                    comment_btn = weibo_elem.find_element(By.CSS_SELECTOR, "[action-type='feed_list_comment']")
                    comment_btn.click()
                    self.random_sleep(2, 3)

                    # æŸ¥æ‰¾è¯„è®º
                    comment_elements = self.driver.find_elements(By.CSS_SELECTOR, ".list_li, [class*='comment']")

                    for comment_elem in comment_elements[:10]:
                        try:
                            username = comment_elem.find_element(By.CSS_SELECTOR, ".name, [class*='name']").text.strip()
                            content = comment_elem.find_element(By.CSS_SELECTOR, ".txt, [class*='text']").text.strip()

                            if username and content:
                                results.append({
                                    'platform': 'å¾®åš',
                                    'username': username,
                                    'content': content,
                                    'source_url': self.driver.current_url,
                                    'scraped_at': datetime.now().isoformat()
                                })

                        except:
                            continue

                except:
                    continue

                self.random_sleep(3, 6)

        except Exception as e:
            print(f"âŒ çˆ¬å–å¤±è´¥: {e}")

        return results

    def filter_high_intent(self, results: List[Dict]) -> List[Dict]:
        """ç­›é€‰é«˜æ„å‘ç”¨æˆ·"""
        print(f"\nğŸ¯ ç­›é€‰é«˜æ„å‘ç”¨æˆ·...")

        intent_keywords = [
            "æƒ³å’¨è¯¢", "æ±‚æ¨è", "æ€ä¹ˆç”³è¯·", "æœ‰æ²¡æœ‰", "æ±‚è”ç³»",
            "åŠ å¾®ä¿¡", "ç§ä¿¡", "æ±‚åŠ©", "è¯·é—®", "äº†è§£ä¸€ä¸‹",
            "æƒ³å»", "æ‰“ç®—", "å‡†å¤‡", "è€ƒè™‘", "æœ‰æ„å‘",
            "æ±‚ä»‹ç»", "æ±‚åˆ†äº«", "æƒ³çŸ¥é“", "æ±‚é—®", "æœ‰äººçŸ¥é“å—"
        ]

        high_intent = []

        for item in results:
            content = item['content'].lower()

            if any(keyword in content for keyword in intent_keywords):
                item['intent_level'] = 'high'
                high_intent.append(item)
            else:
                item['intent_level'] = 'low'

        print(f"âœ… æ‰¾åˆ° {len(high_intent)} ä¸ªé«˜æ„å‘ç”¨æˆ·")

        return high_intent

    def save_to_excel(self, results: List[Dict], filename: str = None):
        """ä¿å­˜åˆ°Excel"""
        if not filename:
            filename = f"{self.platform}_leads_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

        print(f"\nğŸ’¾ ä¿å­˜åˆ°Excel: {filename}")

        try:
            df = pd.DataFrame(results)

            columns = ['platform', 'username', 'content', 'intent_level', 'source_url', 'scraped_at']
            df = df[columns]

            df.to_excel(filename, index=False, engine='openpyxl')

            print(f"âœ… æˆåŠŸä¿å­˜ {len(results)} æ¡æ•°æ®")
            print(f"ğŸ“‚ æ–‡ä»¶ä½ç½®: {os.path.abspath(filename)}")

        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

    def run(self, keyword: str, limit: int = 10):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        config = self.platform_config[self.platform]

        print(f"\n{'='*50}")
        print(f"ğŸš€ {config['name']}è‡ªåŠ¨è·å®¢å·¥å…·")
        print("="*50)

        try:
            # 1. åˆå§‹åŒ–æµè§ˆå™¨
            self.init_driver()

            # 2. ç™»å½•
            if not self.login():
                print("âŒ ç™»å½•å¤±è´¥")
                return

            # 3. æœç´¢å…³é”®è¯
            if not self.search_keyword(keyword):
                print("âŒ æœç´¢å¤±è´¥")
                return

            # 4. çˆ¬å–æ•°æ®
            if self.platform == 'xiaohongshu':
                results = self.scrape_xiaohongshu(keyword, limit)
            elif self.platform == 'zhihu':
                results = self.scrape_zhihu(keyword, limit)
            elif self.platform == 'weibo':
                results = self.scrape_weibo(keyword, limit)
            else:
                print(f"âŒ æš‚ä¸æ”¯æŒ{self.platform}")
                return

            if not results:
                print("âŒ æœªæ‰¾åˆ°æ•°æ®")
                return

            print(f"\n{'='*50}")
            print(f"âœ… æ€»å…±çˆ¬å– {len(results)} æ¡æ•°æ®")
            print("="*50)

            # 5. ç­›é€‰é«˜æ„å‘
            high_intent = self.filter_high_intent(results)

            # 6. ä¿å­˜
            self.save_to_excel(results)

            if high_intent:
                high_intent_filename = f"{self.platform}_high_intent_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                self.save_to_excel(high_intent, high_intent_filename)

            print(f"\n{'='*50}")
            print("ğŸ‰ å®Œæˆ!")
            print("="*50)
            print(f"æ€»æ•°æ®: {len(results)}")
            print(f"é«˜æ„å‘: {len(high_intent)}")

        except Exception as e:
            print(f"\nâŒ è¿è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

        finally:
            if self.driver:
                print("\nâ¸ï¸ æŒ‰å›è½¦å…³é—­æµè§ˆå™¨...")
                input()
                self.driver.quit()


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*50)
    print("ğŸ¯ ä¸­å›½ç¤¾äº¤åª’ä½“è‡ªåŠ¨è·å®¢å·¥å…·")
    print("="*50)

    print("\næ”¯æŒçš„å¹³å°:")
    print("1. å°çº¢ä¹¦ (xiaohongshu)")
    print("2. çŸ¥ä¹ (zhihu)")
    print("3. å¾®åš (weibo)")
    print("4. æŠ–éŸ³ (douyin) - å¼€å‘ä¸­")
    print("5. Bç«™ (bilibili) - å¼€å‘ä¸­")
    print("6. è±†ç“£ (douban) - å¼€å‘ä¸­")

    platform = input("\nè¯·é€‰æ‹©å¹³å° (ä¾‹å¦‚: xiaohongshu): ").strip().lower()
    if platform not in ['xiaohongshu', 'zhihu', 'weibo']:
        print("âŒ æš‚ä¸æ”¯æŒè¯¥å¹³å°")
        return

    keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ (ä¾‹å¦‚: ç¾å›½ç•™å­¦): ").strip()
    if not keyword:
        keyword = "ç¾å›½ç•™å­¦"

    limit = input("è¯·è¾“å…¥è¦çˆ¬å–çš„å†…å®¹æ•°é‡ (é»˜è®¤10): ").strip()
    limit = int(limit) if limit else 10

    headless = input("æ˜¯å¦åå°è¿è¡Œ? (y/n, é»˜è®¤n): ").strip().lower() == 'y'

    # è¿è¡Œ
    scraper = ChinaSocialScraper(platform, headless)
    scraper.run(keyword, limit)


if __name__ == "__main__":
    main()
