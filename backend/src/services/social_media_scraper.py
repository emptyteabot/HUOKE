"""
å°çº¢ä¹¦/çŸ¥ä¹æ•°æ®æŠ“å– - é’ˆå¯¹ç•™å­¦æœºæ„è·å®¢
"""

import requests
from bs4 import BeautifulSoup
import json
import time
from typing import List, Dict
import re

class SocialMediaScraper:
    def __init__(self):
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8'
        }

    def scrape_xiaohongshu_comments(self, post_url: str, cookies: str = None) -> List[Dict]:
        """
        æŠ“å–å°çº¢ä¹¦å¸–å­è¯„è®º
        éœ€è¦æä¾›cookiesæ‰èƒ½è®¿é—®
        """
        print(f"ğŸ” æŠ“å–å°çº¢ä¹¦: {post_url}")

        if cookies:
            self.headers['Cookie'] = cookies

        leads = []

        try:
            response = requests.get(post_url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # å°çº¢ä¹¦çš„è¯„è®ºç»“æ„(éœ€è¦æ ¹æ®å®é™…é¡µé¢è°ƒæ•´)
            comments = soup.find_all('div', class_='comment-item')

            for comment in comments:
                try:
                    username = comment.find('span', class_='username').text.strip()
                    content = comment.find('div', class_='content').text.strip()

                    # åˆ¤æ–­æ˜¯å¦æœ‰ç•™å­¦æ„å‘
                    if self.has_study_abroad_intent(content):
                        lead = {
                            'username': username,
                            'content': content,
                            'platform': 'å°çº¢ä¹¦',
                            'source_url': post_url,
                            'intent_score': self.calculate_intent_score(content)
                        }
                        leads.append(lead)
                        print(f"âœ… å‘ç°æ„å‘ç”¨æˆ·: {username}")

                except Exception as e:
                    continue

        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {e}")

        return leads

    def scrape_zhihu_answers(self, question_url: str) -> List[Dict]:
        """
        æŠ“å–çŸ¥ä¹é—®é¢˜ä¸‹çš„å›ç­”è€…
        """
        print(f"ğŸ” æŠ“å–çŸ¥ä¹: {question_url}")

        leads = []

        try:
            response = requests.get(question_url, headers=self.headers, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')

            # çŸ¥ä¹å›ç­”åˆ—è¡¨
            answers = soup.find_all('div', class_='List-item')

            for answer in answers[:20]:  # åªå–å‰20ä¸ª
                try:
                    # æå–ç”¨æˆ·ä¿¡æ¯
                    author = answer.find('a', class_='UserLink-link')
                    if not author:
                        continue

                    username = author.text.strip()
                    user_url = 'https://www.zhihu.com' + author.get('href', '')

                    # æå–å›ç­”å†…å®¹
                    content_elem = answer.find('div', class_='RichContent-inner')
                    content = content_elem.text.strip() if content_elem else ""

                    # åˆ¤æ–­æ˜¯å¦æœ‰ç•™å­¦æ„å‘
                    if self.has_study_abroad_intent(content):
                        lead = {
                            'username': username,
                            'profile_url': user_url,
                            'content_preview': content[:200],
                            'platform': 'çŸ¥ä¹',
                            'source_url': question_url,
                            'intent_score': self.calculate_intent_score(content)
                        }
                        leads.append(lead)
                        print(f"âœ… å‘ç°æ„å‘ç”¨æˆ·: {username}")

                except Exception as e:
                    continue

            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«

        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {e}")

        return leads

    def scrape_douyin_comments(self, video_id: str) -> List[Dict]:
        """
        æŠ“å–æŠ–éŸ³è§†é¢‘è¯„è®º
        éœ€è¦ä½¿ç”¨Seleniumæˆ–Playwright
        """
        print(f"ğŸ” æŠ“å–æŠ–éŸ³è§†é¢‘: {video_id}")

        # è¿™é‡Œéœ€è¦ä½¿ç”¨Selenium/Playwright
        # å› ä¸ºæŠ–éŸ³æ˜¯åŠ¨æ€åŠ è½½çš„
        leads = []

        # TODO: å®ç°æŠ–éŸ³æŠ“å–é€»è¾‘

        return leads

    def has_study_abroad_intent(self, text: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æœ‰ç•™å­¦æ„å‘"""
        keywords = [
            'ç•™å­¦', 'å‡ºå›½', 'ç”³è¯·', 'æ‰˜ç¦', 'é›…æ€', 'GRE', 'GMAT',
            'ç¾å›½å¤§å­¦', 'è‹±å›½å¤§å­¦', 'åŠ æ‹¿å¤§', 'æ¾³æ´²', 'æ–°åŠ å¡',
            'æœ¬ç§‘ç”³è¯·', 'ç ”ç©¶ç”Ÿç”³è¯·', 'åšå£«ç”³è¯·',
            'ä¸­ä»‹', 'é¡¾é—®', 'æ–‡ä¹¦', 'offer', 'admission'
        ]

        return any(keyword in text for keyword in keywords)

    def calculate_intent_score(self, text: str) -> int:
        """è®¡ç®—æ„å‘è¯„åˆ†"""
        score = 0

        # é«˜æ„å‘å…³é”®è¯
        high_intent = ['æƒ³ç”³è¯·', 'å‡†å¤‡ç”³è¯·', 'æ‰“ç®—å‡ºå›½', 'æ±‚æ¨èä¸­ä»‹', 'éœ€è¦å¸®åŠ©']
        for keyword in high_intent:
            if keyword in text:
                score += 20

        # ä¸­æ„å‘å…³é”®è¯
        medium_intent = ['äº†è§£', 'å’¨è¯¢', 'è€ƒè™‘', 'æœ‰æ²¡æœ‰']
        for keyword in medium_intent:
            if keyword in text:
                score += 10

        # æåˆ°å…·ä½“å­¦æ ¡/ä¸“ä¸š
        if any(word in text for word in ['å“ˆä½›', 'æ–¯å¦ç¦', 'MIT', 'ç‰›æ´¥', 'å‰‘æ¡¥']):
            score += 15

        # æåˆ°é¢„ç®—
        if any(word in text for word in ['é¢„ç®—', 'è´¹ç”¨', 'å¤šå°‘é’±']):
            score += 10

        return min(score, 100)

    def extract_contact_info(self, text: str) -> Dict:
        """æå–è”ç³»æ–¹å¼"""
        contact = {}

        # æå–å¾®ä¿¡å·
        wechat_pattern = r'å¾®ä¿¡[ï¼š:]\s*([a-zA-Z0-9_-]+)'
        wechat_match = re.search(wechat_pattern, text)
        if wechat_match:
            contact['wechat'] = wechat_match.group(1)

        # æå–QQå·
        qq_pattern = r'QQ[ï¼š:]\s*(\d{5,11})'
        qq_match = re.search(qq_pattern, text)
        if qq_match:
            contact['qq'] = qq_match.group(1)

        # æå–é‚®ç®±
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        email_match = re.search(email_pattern, text)
        if email_match:
            contact['email'] = email_match.group(0)

        # æå–æ‰‹æœºå·
        phone_pattern = r'1[3-9]\d{9}'
        phone_match = re.search(phone_pattern, text)
        if phone_match:
            contact['phone'] = phone_match.group(0)

        return contact

    def batch_scrape(self, urls: List[str], platform: str = 'xiaohongshu') -> List[Dict]:
        """æ‰¹é‡æŠ“å–"""
        all_leads = []

        for url in urls:
            print(f"\nğŸ“ å¤„ç†: {url}")

            if platform == 'xiaohongshu':
                leads = self.scrape_xiaohongshu_comments(url)
            elif platform == 'zhihu':
                leads = self.scrape_zhihu_answers(url)
            else:
                continue

            all_leads.extend(leads)
            time.sleep(3)  # é¿å…è¯·æ±‚è¿‡å¿«

        return all_leads


# ä½¿ç”¨ç¤ºä¾‹
def main():
    scraper = SocialMediaScraper()

    # å°çº¢ä¹¦ç•™å­¦ç›¸å…³å¸–å­URLåˆ—è¡¨
    xiaohongshu_urls = [
        'https://www.xiaohongshu.com/explore/xxx',  # æ›¿æ¢ä¸ºå®é™…URL
        # æ›´å¤šURL...
    ]

    # çŸ¥ä¹ç•™å­¦ç›¸å…³é—®é¢˜URLåˆ—è¡¨
    zhihu_urls = [
        'https://www.zhihu.com/question/xxx',  # æ›¿æ¢ä¸ºå®é™…URL
        'https://www.zhihu.com/question/yyy',
    ]

    # æŠ“å–å°çº¢ä¹¦
    print("=" * 50)
    print("å¼€å§‹æŠ“å–å°çº¢ä¹¦...")
    print("=" * 50)
    xhs_leads = scraper.batch_scrape(xiaohongshu_urls, platform='xiaohongshu')

    # æŠ“å–çŸ¥ä¹
    print("\n" + "=" * 50)
    print("å¼€å§‹æŠ“å–çŸ¥ä¹...")
    print("=" * 50)
    zhihu_leads = scraper.batch_scrape(zhihu_urls, platform='zhihu')

    # åˆå¹¶ç»“æœ
    all_leads = xhs_leads + zhihu_leads

    # æŒ‰è¯„åˆ†æ’åº
    all_leads.sort(key=lambda x: x['intent_score'], reverse=True)

    # ä¿å­˜ç»“æœ
    with open('social_media_leads.json', 'w', encoding='utf-8') as f:
        json.dump(all_leads, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å…±æŠ“å– {len(all_leads)} ä¸ªæ½œåœ¨å®¢æˆ·")
    print(f"ğŸ“Š é«˜æ„å‘(>60åˆ†): {len([l for l in all_leads if l['intent_score'] > 60])}")
    print(f"ğŸ“Š ä¸­æ„å‘(30-60åˆ†): {len([l for l in all_leads if 30 < l['intent_score'] <= 60])}")


if __name__ == '__main__':
    main()
